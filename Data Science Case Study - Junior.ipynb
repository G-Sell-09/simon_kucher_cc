{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "27f14d9a-8893-449a-930e-f5d946957a2c",
   "metadata": {},
   "source": [
    "# Problem Description\n",
    "***alles um tier GmBH*** is a pet supplies company. They are currently auditing their promotional activities and the CEO, one of the main stakeholders, feels that the promotions they offer is too generic and not targeted. They have requested us to devise a customer segmentation model that they can use to run targeted promotional activities.\n",
    "\n",
    "The client is interested in seeing what kind of customers are buying at ***alles um tier GmbH***. They assume that, in addition to private individuals, there are also smaller companies that purchase from ***alles um tier GmBH***. The project scope is to build a segmentation model and analyze the resulting customer segments.\n",
    "\n",
    "# Data\n",
    "\n",
    "You are given a dataset at customer level for the past year with the following data points. Number of transactions in the past year (*num_transactions*), order amount the past year (*total_order_value*), days between transactions the past year (*days_between_trans*), re-order rate the past year (*repeat_share*), and % of dog products bought (*dog_share*).\n",
    "\n",
    "### Data Set\n",
    "The dataset consists of 100k rows and has the following columns:\n",
    "\n",
    "* CustomerID (int): UUID for the customer\n",
    "* num_transactions (int): number of transactions in a given year\n",
    "* total_order_value (float): total order value in â‚¬ for the time period\n",
    "* days_between_trans (float): average days between transactions for a user\n",
    "* repeat_share (float): product share repeated every order\n",
    "* dog_share (float): percentage of products ordered that are dog food related\n",
    "    \n",
    "# Technical Environment\n",
    "* Python\n",
    "* numpy\n",
    "* pandas\n",
    "* scikit-learn\n",
    "* matplotlib / scipy / searborn / altair / plotly\n",
    "\n",
    "# Approach\n",
    "The solution is assessed on the following skills:\n",
    "* A thorough evaluation of the data set using statistical measures and visualization\n",
    "* Elegant Python coding skills\n",
    "* Machine learning modelling fundamentals\n",
    "* Model & result evaluation\n",
    "\n",
    "# Output\n",
    "Please provide your solution in a jupyter notebook with clear markdown comments.\n",
    "The final output should be in the form of a DataFrame with two columns, the CustomerId and the assigned cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4acb833",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------\n",
    "--------------------------------------------------------------------------------------------------------------\n",
    "--------------------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22559e30",
   "metadata": {},
   "source": [
    "# Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b57f63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all needed libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import altair as alt\n",
    "import plotly.express as px\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f087c59",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed64ab0-ad74-42b4-a516-857d513a1f2e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# load the data and make sure to specify the correct delimiter\n",
    "df = pd.read_csv(\"DataSet_JuniorCodingChallenge.csv\", delimiter='|')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6727eda2",
   "metadata": {},
   "source": [
    "## Handling Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acf5ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how often two values are missing in one row\n",
    "print(f\"Number of rows with two missing values: {len(df[df.isnull().sum(axis=1) == 2])}\")\n",
    "\n",
    "dropping = len(df[df.isnull().sum(axis=1) == 1])/len(df)\n",
    "print(f\"Percentage of rows with one missing value: {dropping:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37eb4ef",
   "metadata": {},
   "source": [
    "On the one hand, we see that only one entry is missing at a time, so it would make sense to fill in these values. On the other hand, only 0.46 % of all customer data have missing values. It could be argued that it is reasonable to simply drop these values, but due to the fact that only one value is missing at a time, we can e.g. use K-Nearest Neighbors Imputation on all numerical values and fill the missing entries in this way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76dbf0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Create a copy and drop the CustomerID column\n",
    "df_knn = df.drop(columns='CustomerID')\n",
    "\n",
    "# Use KNN imputation to fill in the missing values\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "df_imputed = pd.DataFrame(imputer.fit_transform(df_knn), columns=df_knn.columns)\n",
    "\n",
    "# Print a statemetn that len(df_imputed.isnull().sum()) is 0\n",
    "print(f\"Showcasing the missing values after imputation:\\n{df_imputed.isnull().sum()}\")\n",
    "\n",
    "# # Check the newly filled values\n",
    "# missing_indices = df[df.isnull().sum(axis=1) == 1].index\n",
    "# df.loc[missing_indices]\n",
    "# df_imputed.loc[missing_indices]\n",
    "\n",
    "# Print a statement to that the new values were checked and seem reasonable\n",
    "print(\"The new filled entries were double checked again and they are reasonable.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c0f447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Either drop the missing values or use the imputed data\n",
    "df_drop = df.dropna()\n",
    "\n",
    "# Set df to the imputed data and add the CustomerID column back to the first column\n",
    "df = pd.concat([df['CustomerID'], df_imputed], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18558a30",
   "metadata": {},
   "source": [
    "## Data Integrity Check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3431260",
   "metadata": {},
   "source": [
    "At first we want to make sure that the num_transaction has the correct integer values and that the other numerical features are saved as floats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303900ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the current data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73badef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that counts all entries that are not .00 floats\n",
    "def find_floats(df, column):\n",
    "    count = 0\n",
    "    for i in df[column].unique():\n",
    "        if i % 1 != 0:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "# State how many entries need to be rounded in the num_transactions column\n",
    "print(f\"There are {find_floats(df, 'num_transactions')} entries that are not .00 floats and need to be rounded.\")\n",
    "\n",
    "# Round all float values before converting them to integers\n",
    "df['num_transactions'] = df['num_transactions'].apply(lambda x: round(x))\n",
    "\n",
    "# Double Check if all values are rounded now with a print statement\n",
    "print(f\"There are {find_floats(df, 'num_transactions')} entries that are not .00 floats left.\")\n",
    "\n",
    "# Convert num_transactions to integers\n",
    "df['num_transactions'] = df['num_transactions'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9ae8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check all types again\n",
    "print(\"All data types are correct now.\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d755a0",
   "metadata": {},
   "source": [
    "Now we want to make sure that all numerical values are in reasonable ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f84040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of negative values for num_transactions, total_order_value and days_between_trans for negative values\n",
    "print(f\"Number of negative values for num_transactions: {len(df[df['num_transactions'] < 0])}\")\n",
    "print(f\"Number of negative values for total_order_value: {len(df[df['total_order_value'] < 0])}\")\n",
    "print(f\"Number of negative values for days_between_trans: {len(df[df['days_between_trans'] < 0])}\")\n",
    "\n",
    "# Check repeat_share and dog_share for values between 0 and 1. So count the number of values outside of this range\n",
    "print(f\"Number of values outside of the range [0, 1] for repeat_share: {len(df[(df['repeat_share'] < 0) | (df['repeat_share'] > 1)])}\")\n",
    "print(f\"Number of values outside of the range [0, 1] for dog_share: {len(df[(df['dog_share'] < 0) | (df['dog_share'] > 1)])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b596c3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the negative values in the 3 columns\n",
    "df = df[df['num_transactions'] >= 0]\n",
    "df = df[df['total_order_value'] >= 0]\n",
    "df = df[df['days_between_trans'] >= 0]\n",
    "\n",
    "# Drop the values outside of the range 0 and 1 for the last two columns\n",
    "df = df[(df['repeat_share'] >= 0) & (df['repeat_share'] <= 1)]\n",
    "df = df[(df['dog_share'] >= 0) & (df['dog_share'] <= 1)]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b6f55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find duplicates in the CustomerID column and check whether they are consistent\n",
    "def find_inconsistent_duplicates(df, object_col):\n",
    "    # Get the indices of duplicated entries in the object column\n",
    "    duplicated_indices = df[df.duplicated(subset=[object_col], keep=False)].index\n",
    "\n",
    "    # Dictionary to store the indices of inconsistent duplicates\n",
    "    inconsistent_indices = []\n",
    "\n",
    "    # Group by the object column and iterate over each group\n",
    "    for key, group in df.loc[duplicated_indices].groupby(object_col):\n",
    "        # Get the first row's data (excluding the object column)\n",
    "        reference_row = group.iloc[0, 1:].values\n",
    "        \n",
    "        # Check if all rows in the group match the first row\n",
    "        for idx, row in group.iterrows():\n",
    "            if not (row.iloc[1:].values == reference_row).all():\n",
    "                inconsistent_indices.append(idx)\n",
    "\n",
    "    return inconsistent_indices\n",
    "\n",
    "indices_with_inconsistencies = find_inconsistent_duplicates(df, 'CustomerID')\n",
    "\n",
    "# Print the number of inconsistent duplicates\n",
    "print(f\"Number of inconsistent duplicates: {len(indices_with_inconsistencies)}. This is why we can simply drop one of them.\")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0564692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# State how many CustomerIDs are duplicated and that they will be dropped\n",
    "print(f\"There are {df['CustomerID'].duplicated().sum()} duplicated CustomerIDs. They will be dropped.\")\n",
    "\n",
    "# Drop the duplicated CustomerIDs\n",
    "df = df.drop_duplicates(subset='CustomerID')\n",
    "\n",
    "# Reset the index\n",
    "df = df.reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1cdf69",
   "metadata": {},
   "source": [
    "In this section, we first loaded the data and then checked for missing values and filled them using K-Nearest Neighbors Imputation. We then checked for data integrity by looking at the data types of the columns, at the reasonable ranges of the data and the unique CustomerIDs.\n",
    "\n",
    "Now the data is ready for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d259363",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis **(EDA)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8c206e",
   "metadata": {},
   "source": [
    "## Statistical Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fe4cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary statistics for the data\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735c4298",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7eb26f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a histogram for each column\n",
    "df.hist(figsize=(10, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f08d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_copy = df.drop(columns='CustomerID')\n",
    "\n",
    "# Creating multiple boxplots, one for each column\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i, col in enumerate(df_copy.columns):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    sns.boxplot(x=df_copy[col])\n",
    "    plt.title(col)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876cbbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a correlation matrix and visualize it with a heatmap\n",
    "corr = df_copy.corr()\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbde401",
   "metadata": {},
   "source": [
    "We can see a high correlation between days_between_trans and repeat_share (-0.67). This negative linear relationship suggests that customer who order the same products every time they order, most likely do this in a more frequent way, meaning they for example have the same order on a weekly or 2-weekly basis. This could be a hint that these customers are rather small companies than private customers as they would probably have a lower frequency of orders.\n",
    "\n",
    "There is also a higher correlation between days_between_trans and dog_share (0.41). This one suggests that customers who order less frequently have a higher percentage of dog related products in their order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454cff72",
   "metadata": {},
   "source": [
    "## Feature Relationships and Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5c426d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating pairplots for all numerical data\n",
    "sns.pairplot(df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0161c9",
   "metadata": {},
   "source": [
    "There are many interesting relationships here. The number of transaction and the total order value show in their relationship that customers either order very often for small amounts of money or they rather order selden, but therefore in big volumes. This could again be hint that there are private people ordering more often, but in smaller amounts as they have only themselves they need it for and then on the other hand smaller companies that buy stocks once every month or quarter. \n",
    "\n",
    "Also the number of transactions vs. days between transaction respectively the total order value vs. days between transaction show a similar behavior suiting the previously made statement. It seems that the customers who order less frequently have a lower total order value and of course less transactions (which seems obvious). So the previous made hypothesis seems to be supported. From this we could segment the customers into low-spending infrequent buyers vs. high-spending frequent buyers. This could then be added with a few customers who have an extremly high total order value which might represent the corporate clients which supports the hypothesis given by the company.\n",
    "\n",
    "When looking at the number of transcations / total order value / days between transactions vs the repeated share in every order, we can see these 3 customer segmentations again. There are two strives on the bottom of each graph that seem to be different customer segmentations and then these outliers that seem to be the corporate clients. To better understand the relatinship of the two in strives showing customers segmentations we will now drop the outliers in the data set to get a better feeling for the two mentioned segments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86424959",
   "metadata": {},
   "source": [
    "### Dropping some of the Outliers in a 1st Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba0fe0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 10% outliers from the data in a new copy\n",
    "df_no_outliers = df.copy()\n",
    "\n",
    "# Define the columns to check for outliers\n",
    "columns = ['num_transactions', 'total_order_value', 'days_between_trans', 'repeat_share', 'dog_share']\n",
    "\n",
    "# Iterate over the columns and remove the outliers\n",
    "for col in columns:\n",
    "    # Calculate the z-scores for each value in the column\n",
    "    z_scores = np.abs(stats.zscore(df_no_outliers[col]))\n",
    "\n",
    "    # 99.9% confidence interval (2194 outliers)\n",
    "    outlier_indices = np.where(z_scores > 3.291)[0]\n",
    "\n",
    "    # 99.5% confidence interval (3523 outliers)\n",
    "    # outlier_indices = np.where(z_scores > 2.807)[0]\n",
    "\n",
    "    # 99% confidence interval (4532 outliers)\n",
    "    # outlier_indices = np.where(z_scores > 2.58)[0]\n",
    "\n",
    "    # 95% confidence interval (17560 outliers)\n",
    "    # outlier_indices = np.where(z_scores > 1.96)[0] \n",
    "\n",
    "    # 90% confidence interval (29567 outliers)\n",
    "    # outlier_indices = np.where(z_scores > 1.64)[0]\n",
    "\n",
    "    # Drop the outliers\n",
    "    df_no_outliers = df_no_outliers.drop(index=outlier_indices)\n",
    "\n",
    "    # Reset the index\n",
    "    df_no_outliers = df_no_outliers.reset_index(drop=True)\n",
    "\n",
    "# How many outliers were removed\n",
    "print(f\"{len(df) - len(df_no_outliers)} outliers were removed.\")\n",
    "\n",
    "# Visualize the pairplots for the data without outliers\n",
    "sns.pairplot(df_no_outliers)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9863340c",
   "metadata": {},
   "source": [
    "After trying out different confidence intervals we realized that a 99.9% confidence interval is already sufficient enough to drop all neccessary outliers, which probably represent corporate clients. They will be more specifically characterized later, but for now we can already see more meaningful visualizations of the different relationships.\n",
    "\n",
    "We can now clearly see that the higher the toal order value, the more often the customer order it and the more often they have a higher share of repeated order. Looking at the days between transactions, it is seen that there is one segmentation of customers that have an extremly high period in between transactions and they are also the customers that have a very low number of transactions and a low total order value. It seems like this could be customers who might have just tried out the shop and that were not convinced of the product. This could of course be a segmentation of customers that could be won back with a very special and generous offer.\n",
    "\n",
    "When it comes to the repeat share percentage, there is a linear relationship with the number of transactions and the total order value, meaning that the more the customer orders (more often and bigger volume) the higher is also the repeated order share. Now when it comes to the days between transactions, we can identify two segmentations. The customers who have a low number of days between transactions have a repeat share that is, especially for the customers with the lowest days between transactions, skew to a higher repeat share percentage (10-60%) and on the other side customers who order less frequent and that rather have a repeat share of 5-40%.\n",
    "\n",
    "The dog share percentage seems to be normally distributed across all customers with a slight skew to higher percentages for customers who have a lower total order value and a lower number of transactions. So there could be a slight sign that the one time customers that tried out the shop might have looked for dog related products. This could be used as an information that the previously mentioned special and generous offer should mainly includ dog related products. To get a better insight into which products to offer there, it would be helpful to get more data from different product segments for this segment of customers, maybe even build a model which takes the orders made by these customers and then create specifically suited special offers for every single one on a stochastic calculation what these customers are most likely interested in.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be4e9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix for the data without outliers\n",
    "corr_no_outliers = df_no_outliers.drop(columns='CustomerID').corr()\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(corr_no_outliers, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix without Outliers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b247942d",
   "metadata": {},
   "source": [
    "Some of the things we saw in the pairplots can now be further validated. We can clearly see the very high correlation of the number of transactions and the total order value in the time period of one year. For private customers this seems to be absolutely reasonable as they will oftentimes order in smaller sizes and the more often they order, the higher is their total order value - in comparison to corporate customers who might order less often, but therefore in high total order values.\n",
    " \n",
    "We can also see the negative linear relationship of these two features in regard to the days between transactions. This means that customers who order more often and with a higher total order value, have less days in between each order. This seems to be absolutely comprehensible. The same suggestive hypothesis can be made for the repeating order share and the days between transactions. Customers who order more frequently have a higher repeating order, meaning they have they standard products that they need to have in the houshold at all times and then they order some new things on the side or try out new products. These customers could be targeted especially with new products in the shop and a special offer due to the close relationship with the customer, maybe even offering a membership card with special opportunities and the chance to be the first person ordering new products as a special offering.\n",
    " \n",
    "Something that stands out is the dog share of each order. It seems like that the regularly ordering customers have a rather lower dog food related order. The more often someone orders, the less often they go for dog food. This information can be used in choosing the right products for each customer segement. So it seems that low-spending infrequent buyers rather have a higher dog food related share in their orders than the high-spending frequent buyers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b9a1c2",
   "metadata": {},
   "source": [
    "### Creating one new Feature out of 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a576ed2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Due to the very high linear correlation between num_transactions and total_order_value, we create a combined feature\n",
    "# that represents the average order value per transaction\n",
    "df_no_outliers['avg_order_value'] = df_no_outliers['total_order_value'] / df_no_outliers['num_transactions']\n",
    "\n",
    "# Set the new column as the first column and drop the old columns\n",
    "df_no_outliers = df_no_outliers[['CustomerID', 'avg_order_value', 'days_between_trans', 'repeat_share', 'dog_share']]\n",
    "\n",
    "\n",
    "# ALso do this for the original data\n",
    "df['avg_order_value'] = df['total_order_value'] / df['num_transactions']\n",
    "# df = df[['CustomerID', 'avg_order_value', 'days_between_trans', 'repeat_share', 'dog_share']]\n",
    "\n",
    "# Check the new data\n",
    "df_no_outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba88adb5",
   "metadata": {},
   "source": [
    "### Visualizing the Dataset with new Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbca76f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the pairplots for the new data without outliers\n",
    "sns.pairplot(df_no_outliers)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12022b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix for the data without outliers\n",
    "corr_no_outliers = df_no_outliers.drop(columns='CustomerID').corr()\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(corr_no_outliers, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix without Outliers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ae7595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only visualize the avg_order_value column in a boxplot, but make two plots left and right.\n",
    "# One plot with the original data and one without the outliers\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.boxplot(x=df['avg_order_value'])\n",
    "plt.title('Original Data')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(x=df_no_outliers['avg_order_value'])\n",
    "plt.title('Data without Outliers')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f9813f",
   "metadata": {},
   "source": [
    "### Precisely Finding the Outliers (Corporate Customers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09aa443",
   "metadata": {},
   "source": [
    "Now that we have a more robust understanding of the data and the newly created feature, we can use that feature to filter out more precisely the corporate customers. We are therefore first using a classic approach to identify outliers, the Initerquartile Range. Afterwards we will by hand look for a precise boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb811f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is obvious that the avg_order_value column has a lot of outliers. What is the best way to identify how many outliers there are?\n",
    "# We can use the IQR method to identify the outliers in the avg_order_value column\n",
    "Q1 = df_no_outliers['avg_order_value'].quantile(0.25)\n",
    "Q3 = df_no_outliers['avg_order_value'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Calculate the number of outliers\n",
    "outliers = df[(df['avg_order_value'] < (Q1 - 1.5 * IQR)) | (df['avg_order_value'] > (Q3 + 1.5 * IQR))]\n",
    "print(f\"Number of outliers in the avg_order_value column: {len(outliers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87599a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the original data and rank the dataset by the avg_order_value column in descending order\n",
    "df_ranked = df.sort_values(by='avg_order_value', ascending=False).reset_index(drop=True)\n",
    "df_ranked.head(len(outliers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b456913e",
   "metadata": {},
   "source": [
    "Here we can now clearly see a boundary and it seems more than reasonable to cut the dataset into the first 96 customers and then the rest which we from now on will assume to be private customers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cf8544",
   "metadata": {},
   "source": [
    "### Dividing the Dataset into Corporate and Private Customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacdfe9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the corporate custome datarframe by using only the first 96 rows\n",
    "df_corporate = df_ranked.head(96)\n",
    "df_corporate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63cc954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the private customer dataframe by using the remaining rows\n",
    "df_private = df_ranked.iloc[96:]\n",
    "df_private = df_private.reset_index(drop=True)\n",
    "df_private"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa59e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))  # Adjust the figure size for four plots\n",
    "\n",
    "# First row: Boxplots\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.boxplot(x=df_corporate['avg_order_value'])\n",
    "plt.title('Corporate Customers - Boxplot')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.boxplot(x=df_private['avg_order_value'])\n",
    "plt.title('Private Customers - Boxplot')\n",
    "\n",
    "# Second row: Histograms\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.histplot(df_corporate['avg_order_value'], bins=20)\n",
    "plt.title('Corporate Customers - Histogram')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.histplot(df_private['avg_order_value'], bins=20)\n",
    "plt.title('Private Customers - Histogram')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb2d311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the correlation matrix for the corporate customers in a plot with two plots on the left, and on the right the private customers\n",
    "plt.figure(figsize=(24, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.heatmap(df_corporate.drop(columns=['CustomerID', 'total_order_value','num_transactions']).corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix - Corporate Customers')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.heatmap(df_private.drop(columns=['CustomerID', 'total_order_value','num_transactions']).corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix - Private Customers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d121a9d",
   "metadata": {},
   "source": [
    "We are now able to analyse each customer segmentation in a more precisey way. We can already see clear differences.\n",
    "\n",
    "Corporate Customers:\n",
    "\n",
    "On the left hand side the corporate customers, which order less frequent the higher their average order value was - something that makes absolute sense. Then we can also see that the customers who more frequently order also have a higher repeating order share. This again makes sense as they are running out of specific product more quickly (as they also order less on average due to the first finding) and therefore need the same products more often. Lastly the dog related food products in each order. There seems to be a slight higher dog related food order for companies with a higher average order value. This feature should be more closely analyzed afterwards.\n",
    "\n",
    "\n",
    "Private Customers:\n",
    "\n",
    "On the right hand side the private customers, where we can see a very different behaviour when it comes to the average order value and the days between transactions. It seems that the higher the average order value, the more frequently the customer orders. It seems reasonable to make the hypothesis that we can divide the customer side into high-spending frequent buyers and low-spending infrequent buyers once again. This is also supported by the strong linear relationship of the average order value and the repeating share. It seems like the high-spending frequent buyers also order the same products very often. Interestingly, different to the corporate customers, the higher spending customers on average buy less dog food related products. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f41b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the corporate customers in a 3d scatter plot using the average order value, the days between transactions and the dog share, but color the points by the repeat share\n",
    "fig = px.scatter_3d(df_corporate, x='avg_order_value', y='days_between_trans', z='dog_share', color='repeat_share')\n",
    "\n",
    "# Set the size of the figure\n",
    "fig.update_layout(width=1600, height=800)\n",
    "\n",
    "fig.update_layout(title='Corporate Customers - 3D Scatter Plot')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb54db5",
   "metadata": {},
   "source": [
    "With this plot we already get a good feeling of the rather small dataset of corporate customers. From more frequently ordering corporates with rather low average order value and a fairly equally distributed dog food related share (from about 3 to 50%) to the less frequent, but therefore rather higher per order spending corporates with a not distinctly seperatable dog share percentage. There is one high spending per order corporate with a really high dog share of about 62%, but also one with only 8%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d54b605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now the same for the private customers\n",
    "fig = px.scatter_3d(df_private, x='avg_order_value', y='days_between_trans', z='dog_share', color='repeat_share')\n",
    "\n",
    "# Set the size of the figure\n",
    "fig.update_layout(width=1600, height=800)\n",
    "\n",
    "fig.update_layout(title='Private Customers - 3D Scatter Plot')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9a1e11",
   "metadata": {},
   "source": [
    "In this plot we can see that there are some weird looking data points with days of more than 364 in between transactions. Due to the knowledge of a given data set of the last year this has to be an error. Something we should look at more closely next.\n",
    "\n",
    "Also there is one very interesting customer with a very high dog share percentage and a really high average order value that seems to order every two days. This customer should be analyzed separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494e2130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out the private customers that have a days_between_trans value of higher than 364 (the maximum)\n",
    "df_private_hd = df_private[df_private['days_between_trans'] > 364]\n",
    "\n",
    "# Visualize the private customers with a days_between_trans of more than 364 days in a 3d scatter plot\n",
    "fig = px.scatter_3d(df_private_hd, x='avg_order_value', y='days_between_trans', z='dog_share', color='repeat_share')\n",
    "\n",
    "# Set the size of the figure\n",
    "fig.update_layout(width=1600, height=800)\n",
    "\n",
    "fig.update_layout(title='Private Customers with more than 364 days between transactions - 3D Scatter Plot')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5a1164",
   "metadata": {},
   "source": [
    "Except for their off looking number of days between transactions the data seems to be reasonable. Therefore we will simply set the number of days_between_transaction to a reasonable value. We will therefore have a closer look at the most outstanding data points in that regard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12a500d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the private customers again with the 3d scatter plot but without the customers that have more than 364 days between transactions\n",
    "fig = px.scatter_3d(df_private[df_private['days_between_trans'] <= 364], x='avg_order_value', y='days_between_trans', z='dog_share', color='repeat_share')\n",
    "fig.update_layout(width=1600, height=800)\n",
    "fig.update_layout(title='Private Customers - 3D Scatter Plot')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dec809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the number of customers that have a days_between\n",
    "print(f\"Number of private customers that have more than 364 days between transactions: {len(df_private[df_private['days_between_trans'] > 364])}\")\n",
    "print(f\"Number of private customers that have more than 240 days between transactions: {len(df_private[df_private['days_between_trans'] > 240])}\")\n",
    "print(f\"Number of private customers that have more than 236 days between transactions: {len(df_private[df_private['days_between_trans'] > 236])}\")\n",
    "print(f\"Number of private customers that have more than 235 days between transactions: {len(df_private[df_private['days_between_trans'] > 235])}\")\n",
    "print(f\"Number of private customers that have more than 234 days between transactions: {len(df_private[df_private['days_between_trans'] > 234])}\")\n",
    "print(f\"Number of private customers that have more than 233 days between transactions: {len(df_private[df_private['days_between_trans'] > 233])}\")\n",
    "print(f\"Number of private customers that have more than 1000 days between transactions: {len(df_private[df_private['days_between_trans'] > 1000])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8777dfd3",
   "metadata": {},
   "source": [
    "Looking at these numbers, the previous plot and having in mind the total size of the private customer data set it seems reasonable to either set the boundary at 235 or 236. Moving on we will set all values above 235 to the value of 235, so that later segmentations can be done more usefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8512b623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of days between transactions to 235 for the private customers that have more than 235 days\n",
    "df_private.loc[df_private['days_between_trans'] > 235, 'days_between_trans'] = 235\n",
    "\n",
    "# Visualize the private customers again with the 3d scatter plot\n",
    "fig = px.scatter_3d(df_private, x='avg_order_value', y='days_between_trans', z='dog_share', color='repeat_share')\n",
    "\n",
    "# Set the size of the figure\n",
    "fig.update_layout(width=1600, height=800)\n",
    "\n",
    "fig.update_layout(title='Private Customers - 3D Scatter Plot')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229cd24d",
   "metadata": {},
   "source": [
    "Now this plot gives us a great inside into how the private customer data set is distributed and we can already see 3 different segments of customers. For now there are still 3 customers that stand out. They have a high average order value and order about every second day with a very high repeating share of products. We will filter them out specifically now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094bf822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out the private customers with a higher average order value of 40\n",
    "df_private_hao = df_private[df_private['avg_order_value'] > 40]\n",
    "df_private_hao"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc1c6e8",
   "metadata": {},
   "source": [
    "These 3 customers should be contacted with a individual marketing strategy. We will drop them out of the continuing data set and come back to them at the end when recommending a marketing strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e8161f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the df_private_hao from the df_private dataframe\n",
    "df_private = df_private[df_private['avg_order_value'] <= 40]\n",
    "\n",
    "# Visualize the private customers again with the 3d scatter plot\n",
    "fig = px.scatter_3d(df_private, x='avg_order_value', y='days_between_trans', z='dog_share', color='repeat_share')\n",
    "\n",
    "# Set the size of the figure\n",
    "fig.update_layout(width=1600, height=800)\n",
    "\n",
    "fig.update_layout(title='Private Customers - 3D Scatter Plot')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96f3b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter all customers that have a days_between_trans of 235 and average oder value of above 20 and a repeat share of above 0.6\n",
    "df_private_filtered = df_private[(df_private['days_between_trans'] == 235) & (df_private['avg_order_value'] > 20) & (df_private['repeat_share'] > 0.6)]\n",
    "df_private_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729897db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check both the CustomerID in the original data\n",
    "df[df['CustomerID'].isin(df_private_filtered['CustomerID'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83739d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check both the CustomerID in the original data\n",
    "df_private[df_private['CustomerID'].isin(df_private_filtered['CustomerID'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34dd5db",
   "metadata": {},
   "source": [
    "Seeing these two customers in the data set it seems more reasonable that the commata was set in the wrong way and that both these customers rather have about 2.3 days in between each transaction. Therefore we will change their value accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52cccbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the df_private dataframe we will change the days_between_trans value to the value in the df dataframe, but we move the commata 3 values to the left\n",
    "df_private.loc[df_private['CustomerID'].isin(df_private_filtered['CustomerID']), 'days_between_trans'] = df.loc[df['CustomerID'].isin(df_private_filtered['CustomerID']), 'days_between_trans'].values / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f966ae5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the private customers again with the 3d scatter plot\n",
    "fig = px.scatter_3d(df_private, x='avg_order_value', y='days_between_trans', z='dog_share', color='repeat_share')\n",
    "\n",
    "# Set the size of the figure\n",
    "fig.update_layout(width=1600, height=800)\n",
    "\n",
    "fig.update_layout(title='Private Customers - 3D Scatter Plot')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339d48c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframes to csv files\n",
    "df_corporate.to_csv('corporate_customers.csv', index=False)\n",
    "df_private.to_csv('private_customers.csv', index=False)\n",
    "df.to_csv('cleaned_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68500046",
   "metadata": {},
   "source": [
    "Now our data sets and features are finally prepared. In the followoing we will precisely analyse the clusters and do a segmentation analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad09f47",
   "metadata": {},
   "source": [
    "# Clustering and Semntation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8d3e0f",
   "metadata": {},
   "source": [
    "What was done so far:\n",
    "...\n",
    "\n",
    "What we want to do next:\n",
    "...\n",
    "\n",
    "Where we want to end at the end:\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707ef3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load both dataframes again\n",
    "df_corporate = pd.read_csv('corporate_customers.csv')\n",
    "df_private = pd.read_csv('private_customers.csv')\n",
    "df = pd.read_csv('cleaned_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8765b3d6",
   "metadata": {},
   "source": [
    "## Corporate Customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d86c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the corporate customers\n",
    "fig = px.scatter_3d(df_corporate, x='avg_order_value', y='days_between_trans', z='dog_share', color='repeat_share')\n",
    "\n",
    "# Set the size of the figure\n",
    "fig.update_layout(width=1600, height=800)\n",
    "\n",
    "fig.update_layout(title='Corporate Customers - 3D Scatter Plot')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3aa20ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the corporate customers\n",
    "fig = px.scatter_3d(df_corporate, x='total_order_value', y='days_between_trans', z='dog_share', color='repeat_share')\n",
    "\n",
    "# Set the size of the figure\n",
    "fig.update_layout(width=1600, height=800)\n",
    "\n",
    "fig.update_layout(title='Corporate Customers - 3D Scatter Plot')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d3f6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_corporate create a copy of the dataframe and rank it by the column total_order_value\n",
    "df_corporate_ranked = df_corporate.sort_values(by='total_order_value', ascending=False).reset_index(drop=True)\n",
    "df_corporate_ranked.iloc[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb65b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corporate_ranked.iloc[40:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0962db08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use k-means clustering to cluster the corporate customers into two groups\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Create a copy of the corporate customers dataframe\n",
    "df_corporate_cluster = df_corporate.copy()\n",
    "\n",
    "# Drop the CustomerID column, the total_order_value column and the num_transactions column\n",
    "df_corporate_cluster = df_corporate_cluster.drop(columns=['CustomerID', 'total_order_value', 'num_transactions'])\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the data\n",
    "df_corporate_cluster_scaled = scaler.fit_transform(df_corporate_cluster)\n",
    "\n",
    "# Create the KMeans model with 2 clusters\n",
    "kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "kmeans.fit(df_corporate_cluster_scaled)\n",
    "\n",
    "# Add the cluster labels to the dataframe\n",
    "df_corporate['cluster'] = kmeans.labels_\n",
    "\n",
    "# Visualize the clusters in a 3D scatter plot\n",
    "fig = px.scatter_3d(df_corporate, x='avg_order_value', y='days_between_trans', z='dog_share', color='cluster')\n",
    "fig.update_layout(width=1600, height=800)\n",
    "fig.update_layout(title='Corporate Customers - 3D Scatter Plot with Clusters')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749b6fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use k-means clustering to cluster the corporate customers into two groups\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Create a copy of the corporate customers dataframe\n",
    "df_corporate_cluster = df_corporate.copy()\n",
    "\n",
    "# Drop the CustomerID column, the total_order_value column and the num_transactions column\n",
    "df_corporate_cluster = df_corporate_cluster.drop(columns=['CustomerID', 'avg_order_value', 'num_transactions'])\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the data\n",
    "df_corporate_cluster_scaled = scaler.fit_transform(df_corporate_cluster)\n",
    "\n",
    "# Create the KMeans model with 2 clusters\n",
    "kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "kmeans.fit(df_corporate_cluster_scaled)\n",
    "\n",
    "# Add the cluster labels to the dataframe\n",
    "df_corporate['cluster'] = kmeans.labels_\n",
    "\n",
    "# Visualize the clusters in a 3D scatter plot\n",
    "fig = px.scatter_3d(df_corporate, x='total_order_value', y='days_between_trans', z='dog_share', color='cluster')\n",
    "fig.update_layout(width=1600, height=800)\n",
    "fig.update_layout(title='Corporate Customers - 3D Scatter Plot with Clusters')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5993b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use k-means clustering to cluster the corporate customers into two groups\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Create a copy of the corporate customers dataframe\n",
    "df_corporate_cluster = df_corporate.copy()\n",
    "\n",
    "# Drop the CustomerID column, the total_order_value column and the num_transactions column\n",
    "df_corporate_cluster = df_corporate_cluster.drop(columns=['CustomerID', 'total_order_value', 'num_transactions'])\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the data\n",
    "df_corporate_cluster_scaled = scaler.fit_transform(df_corporate_cluster)\n",
    "\n",
    "# Create the KMeans model with 3 clusters\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "kmeans.fit(df_corporate_cluster_scaled)\n",
    "\n",
    "# Add the cluster labels to the dataframe\n",
    "df_corporate['cluster'] = kmeans.labels_\n",
    "\n",
    "# Visualize the clusters in a 3D scatter plot\n",
    "fig = px.scatter_3d(df_corporate, x='avg_order_value', y='days_between_trans', z='dog_share', color='cluster')\n",
    "fig.update_layout(width=1600, height=800)\n",
    "fig.update_layout(title='Corporate Customers - 3D Scatter Plot with Clusters')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e1870a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use k-means clustering to cluster the corporate customers into two groups\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Create a copy of the corporate customers dataframe\n",
    "df_corporate_cluster = df_corporate.copy()\n",
    "\n",
    "# Drop the CustomerID column, the total_order_value column and the num_transactions column\n",
    "df_corporate_cluster = df_corporate_cluster.drop(columns=['CustomerID', 'avg_order_value', 'num_transactions'])\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the data\n",
    "df_corporate_cluster_scaled = scaler.fit_transform(df_corporate_cluster)\n",
    "\n",
    "# Create the KMeans model with 3 clusters\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "kmeans.fit(df_corporate_cluster_scaled)\n",
    "\n",
    "# Add the cluster labels to the dataframe\n",
    "df_corporate['cluster'] = kmeans.labels_\n",
    "\n",
    "# Visualize the clusters in a 3D scatter plot\n",
    "fig = px.scatter_3d(df_corporate, x='total_order_value', y='days_between_trans', z='dog_share', color='cluster')\n",
    "fig.update_layout(width=1600, height=800)\n",
    "fig.update_layout(title='Corporate Customers - 3D Scatter Plot with Clusters')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c54e0d6",
   "metadata": {},
   "source": [
    "The k-means algorithm helps to get an understanding how on the used metric we can split this data set. In regard of our marketing strategies, it seems like is a different approach more applicable. Especially because we are talking about only 96 corporate customers, it makes sense to use a rather by hand approach. Here it makes sense to divide the corporate customers into a matrix total order value and the number of transactions on the side, once categorized to high and low. The boundary is simply set by using the average of each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabf9571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Create a copy of the corporate customers dataframe\n",
    "df_corporate_split = df_corporate.copy()\n",
    "\n",
    "# Calculate the mean for total_order_value and num_transactions\n",
    "mean_total_order_value = df_corporate_split['total_order_value'].mean()\n",
    "mean_num_transactions = df_corporate_split['num_transactions'].mean()\n",
    "\n",
    "# Split based on whether the values are above or below the mean\n",
    "df_corporate_split['total_order_value_split'] = df_corporate_split['total_order_value'].apply(\n",
    "    lambda x: 'low' if x < mean_total_order_value else 'high'\n",
    ")\n",
    "\n",
    "df_corporate_split['num_transactions_split'] = df_corporate_split['num_transactions'].apply(\n",
    "    lambda x: 'low' if x < mean_num_transactions else 'high'\n",
    ")\n",
    "\n",
    "# Combine the two splits into a single group variable for four distinct categories\n",
    "df_corporate_split['group'] = (\n",
    "    df_corporate_split['total_order_value_split'].astype(str) + '_' +\n",
    "    df_corporate_split['num_transactions_split'].astype(str)\n",
    ")\n",
    "\n",
    "# Visualize the 2x2 grid in a 3D scatter plot with four different colors\n",
    "fig = px.scatter_3d(\n",
    "    df_corporate_split,\n",
    "    x='total_order_value',\n",
    "    y='days_between_trans',\n",
    "    z='dog_share',\n",
    "    color='group',  # Use the combined group variable for color\n",
    "    symbol='group',  # Optionally, use different symbols for clarity\n",
    "    labels={\n",
    "        'total_order_value': 'Total Order Value',\n",
    "        'days_between_trans': 'Days Between Transactions',\n",
    "        'dog_share': 'Dog Share',\n",
    "        'group': 'Group'\n",
    "    }\n",
    ")\n",
    "fig.update_layout(\n",
    "    width=1600,\n",
    "    height=800,\n",
    "    title='Corporate Customers - 3D Scatter Plot with 2x2 Grid (Split by Mean)',\n",
    "    legend_title_text='Group (Total Order Value vs Num Transactions)'\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "# Set the found clusters as df_corporate['cluster']\n",
    "df_corporate['cluster'] = df_corporate_split['group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e92f2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import plotly.express as px\n",
    "\n",
    "# # Create a copy of the corporate customers dataframe\n",
    "# df_corporate_split = df_corporate.copy()\n",
    "\n",
    "# # Calculate the mean for total_order_value and num_transactions\n",
    "# mean_total_order_value = df_corporate_split['avg_order_value'].mean()\n",
    "# mean_num_transactions = df_corporate_split['num_transactions'].mean()\n",
    "\n",
    "# # Split based on whether the values are above or below the mean\n",
    "# df_corporate_split['total_order_value_split'] = df_corporate_split['avg_order_value'].apply(\n",
    "#     lambda x: 'low' if x < mean_total_order_value else 'high'\n",
    "# )\n",
    "\n",
    "# df_corporate_split['num_transactions_split'] = df_corporate_split['num_transactions'].apply(\n",
    "#     lambda x: 'low' if x < mean_num_transactions else 'high'\n",
    "# )\n",
    "\n",
    "# # Combine the two splits into a single group variable for four distinct categories\n",
    "# df_corporate_split['group'] = (\n",
    "#     df_corporate_split['total_order_value_split'].astype(str) + '_' +\n",
    "#     df_corporate_split['num_transactions_split'].astype(str)\n",
    "# )\n",
    "\n",
    "# # Visualize the 2x2 grid in a 3D scatter plot with four different colors\n",
    "# fig = px.scatter_3d(\n",
    "#     df_corporate_split,\n",
    "#     x='avg_order_value',\n",
    "#     y='days_between_trans',\n",
    "#     z='dog_share',\n",
    "#     color='group',  # Use the combined group variable for color\n",
    "#     symbol='group',  # Optionally, use different symbols for clarity\n",
    "#     labels={\n",
    "#         'avg_order_value': 'avg_order_value',\n",
    "#         'days_between_trans': 'Days Between Transactions',\n",
    "#         'dog_share': 'Dog Share',\n",
    "#         'group': 'Group'\n",
    "#     }\n",
    "# )\n",
    "# fig.update_layout(\n",
    "#     width=1600,\n",
    "#     height=800,\n",
    "#     title='Corporate Customers - 3D Scatter Plot with 2x2 Grid (Split by Mean)',\n",
    "#     legend_title_text='Group (Total Order Value vs Num Transactions)'\n",
    "# )\n",
    "# fig.show()\n",
    "\n",
    "# # Set the found clusters as df_corporate['cluster']\n",
    "# df_corporate['cluster'] = df_corporate_split['group']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1177a836",
   "metadata": {},
   "source": [
    "## 2x2 Matrix: Customer Segmentation Based on Total Order Value and Number of Transactions\n",
    "\n",
    "|                          | **Low Number of Transactions** <br> (Customers below Average Transactions Number) | **High Number of Transactions** <br> (Customers above Average Transactions Number) |\n",
    "|--------------------------|-----------------------------------------------------------------------------|-----------------------------------------------------------------------------|\n",
    "| **Low Total Order Value** <br> (Customers below Average Order Value) | **Budget-Conscious Occasional Customers** <br> These customers make infrequent purchases and spend a low total amount. They may be cost-sensitive or not heavily engaged. | **Budget-Conscious Frequent Customers** <br> These customers make frequent purchases but still maintain a relatively low total order value, indicating smaller transaction sizes. |\n",
    "| **High Total Order Value** <br> (Customers above Average Order Value) | **High-Spending Occasional Customers** <br> These customers do not transact often, but when they do, they tend to spend a significant amount. They might be selective but valuable. | **High-Spending Frequent Customers** <br> These are highly valuable customers who make frequent purchases with high total order value, indicating strong engagement and consistent spending. |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79613b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corporate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4dfaba",
   "metadata": {},
   "source": [
    "Having these 4 segmentations we can develop a marketing strategy customized for each one. When it comes to the dog_share value, there is no clear indication here for the different segments. It might be useful to simply split the dog_share value into 3 intervals and depending on each interval the content of the marketing strategy is adapted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3496f8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I would now like to use Altair to create a linked histogram that is filtered based on a selection of the scatter plot. Use the corporate customers dataframe for this task.\n",
    "import altair as alt\n",
    "\n",
    "# Create the scatter plot\n",
    "scatter = alt.Chart(df_corporate).mark_circle().encode(\n",
    "    x='avg_order_value',\n",
    "    y='days_between_trans',\n",
    "    color='repeat_share',\n",
    "    tooltip=['CustomerID', 'avg_order_value', 'days_between_trans', 'repeat_share']\n",
    ").properties(\n",
    "    width=800,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "# Create the histogram\n",
    "hist = alt.Chart(df_corporate).mark_bar().encode(\n",
    "    x='count()',\n",
    "    y='repeat_share',\n",
    "    color='repeat_share',\n",
    "    tooltip=['repeat_share']\n",
    ").properties(\n",
    "    width=800,\n",
    "    height=200\n",
    ").interactive()\n",
    "\n",
    "# Combine the scatter plot and the histogram\n",
    "scatter & hist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a306355",
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "\n",
    "# Scatter plot with color based on 'cluster'\n",
    "scatter_plot = alt.Chart(df_corporate).mark_circle(size=60).encode(\n",
    "    x=alt.X('avg_order_value', title='Average Order Value'),\n",
    "    y=alt.Y('days_between_trans', title='Days Between Transactions'),\n",
    "    color=alt.Color('cluster:N', scale=alt.Scale(scheme='category10'), title='Customer Segment'),\n",
    "    tooltip=['CustomerID', 'avg_order_value', 'days_between_trans', 'repeat_share']\n",
    ").properties(\n",
    "    width=1200,\n",
    "    height=800,\n",
    "    title=\"Customer Segments by Order Value and Days Between Transactions\"\n",
    ").interactive()\n",
    "\n",
    "scatter_plot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d38d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "\n",
    "# Prepare data for average metrics per cluster\n",
    "avg_metrics = df_corporate.groupby('cluster').agg(\n",
    "    avg_order_value=('avg_order_value', 'mean'),\n",
    "    avg_days_between_trans=('days_between_trans', 'mean'),\n",
    "    avg_repeat_share=('repeat_share', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "# Transform the data from wide format to long format for easier plotting\n",
    "avg_metrics_melted = avg_metrics.melt(id_vars='cluster', \n",
    "                                      value_vars=['avg_order_value', 'avg_days_between_trans', 'avg_repeat_share'], \n",
    "                                      var_name='Metric', \n",
    "                                      value_name='Value')\n",
    "\n",
    "# Bar chart for average metrics per cluster\n",
    "avg_bar_chart = alt.Chart(avg_metrics_melted).mark_bar().encode(\n",
    "    x=alt.X('Metric:N', title='Metric'),\n",
    "    y=alt.Y('Value:Q', title='Average Value'),\n",
    "    color=alt.Color('cluster:N', scale=alt.Scale(scheme='category10'), title='Customer Segment'),\n",
    "    column=alt.Column('cluster:N', title='Customer Segment'),\n",
    "    tooltip=['cluster', 'Metric', 'Value']\n",
    ").properties(\n",
    "    width=300,\n",
    "    height=600,\n",
    "    title=\"Average Metrics by Customer Segment\"\n",
    ").interactive()\n",
    "\n",
    "avg_bar_chart.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c11ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corporate['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebed5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of average order value vs days between transactions, color-coded by segment\n",
    "heatmap = alt.Chart(df_corporate).mark_rect().encode(\n",
    "    x=alt.X('avg_order_value:Q', bin=alt.Bin(maxbins=20), title='Average Order Value'),\n",
    "    y=alt.Y('days_between_trans:Q', bin=alt.Bin(maxbins=20), title='Days Between Transactions'),\n",
    "    color=alt.Color('count():Q', scale=alt.Scale(scheme='blues'), title='Customer Count'),\n",
    "    facet=alt.Facet('cluster:N', title='Customer Segment'),\n",
    "    tooltip=['avg_order_value', 'days_between_trans', 'cluster', 'count()']\n",
    ").properties(\n",
    "    width=300,\n",
    "    height=600,\n",
    "    title=\"Customer Distribution by Order Value and Transaction Frequency per Segment\"\n",
    ").interactive()\n",
    "\n",
    "heatmap.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d0a67f",
   "metadata": {},
   "source": [
    "## Private Customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368f0c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index of df_private\n",
    "df_private = df_private.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cd62db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the corporate customers\n",
    "fig = px.scatter_3d(df_private, x='avg_order_value', y='days_between_trans', z='dog_share', color='repeat_share')\n",
    "\n",
    "# Set the size of the figure\n",
    "fig.update_layout(width=1600, height=800)\n",
    "\n",
    "fig.update_layout(title='Corporate Customers - 3D Scatter Plot')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddab2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the corporate customers\n",
    "fig = px.scatter_3d(df_private, x='total_order_value', y='days_between_trans', z='dog_share', color='repeat_share')\n",
    "\n",
    "# Set the size of the figure\n",
    "fig.update_layout(width=1600, height=800)\n",
    "\n",
    "fig.update_layout(title='Corporate Customers - 3D Scatter Plot')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58427d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster one group out of the private customers. These are the ones with days_between_trans of below 5. Filter them out and create a new dataframe\n",
    "df_private_cluster1 = df_private[df_private['days_between_trans'] < 5]\n",
    "df_private_cluster1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a6fc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create df_private_cluster2 by filtering out the private customers that are in df_private_cluster1\n",
    "df_private_cluster_rest = df_private[~df_private['CustomerID'].isin(df_private_cluster1['CustomerID'])]\n",
    "df_private_cluster_rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13ac529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the corporate customers\n",
    "fig = px.scatter_3d(df_private_cluster_rest, x='avg_order_value', y='days_between_trans', z='dog_share', color='repeat_share')\n",
    "\n",
    "# Set the size of the figure\n",
    "fig.update_layout(width=1600, height=800)\n",
    "\n",
    "fig.update_layout(title='Corporate Customers - 3D Scatter Plot')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e40501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the corporate customers\n",
    "fig = px.scatter_3d(df_private_cluster_rest, x='total_order_value', y='days_between_trans', z='dog_share', color='repeat_share')\n",
    "\n",
    "# Set the size of the figure\n",
    "fig.update_layout(width=1600, height=800)\n",
    "\n",
    "fig.update_layout(title='Corporate Customers - 3D Scatter Plot')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197145f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now I want to use Altair to create a scatter plot for the private customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f43d9e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a3bf0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe9f10e7",
   "metadata": {},
   "source": [
    "Now filter out dog food related customers who order every 6 month or only once in the time frame and that might get won back with special dog related marketing offers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d7c4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now filter out cluster2 from the private customers. These are the ones with a repeat_share of below 0.3 but a dog_share of above 0.29\n",
    "df_private_cluster2 = df_private_cluster_rest[(df_private_cluster_rest['repeat_share'] < 0.3) & (df_private_cluster_rest['dog_share'] > 0.25)]\n",
    "\n",
    "# Create df_private_cluster3 by filtering out the private customers that are in df_private_cluster2\n",
    "df_private_cluster_rest = df_private_cluster_rest[~df_private_cluster_rest['CustomerID'].isin(df_private_cluster2['CustomerID'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd666089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the corporate customers\n",
    "fig = px.scatter_3d(df_private_cluster_rest, x='total_order_value', y='days_between_trans', z='dog_share', color='repeat_share')\n",
    "\n",
    "# Set the size of the figure\n",
    "fig.update_layout(width=1600, height=800)\n",
    "\n",
    "fig.update_layout(title='Corporate Customers - 3D Scatter Plot')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46374a89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7710d201",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637d0311",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d375fe2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1549d425",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaac14d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3052aedd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08ab8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use k-means to cluster the private customers into three groups\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Create a copy of the private customers dataframe\n",
    "df_private_cluster = df_private.copy()\n",
    "\n",
    "# Drop the CustomerID column, the total_order_value column and the num_transactions column\n",
    "df_private_cluster = df_private_cluster.drop(columns=['CustomerID', 'total_order_value'])\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the data\n",
    "df_private_cluster_scaled = scaler.fit_transform(df_private_cluster)\n",
    "\n",
    "# Create the KMeans model with 3 clusters\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "kmeans.fit(df_private_cluster_scaled)\n",
    "\n",
    "# Add the cluster labels to the dataframe\n",
    "df_private['cluster'] = kmeans.labels_\n",
    "\n",
    "# Visualize the clusters in a 3D scatter plot\n",
    "fig = px.scatter_3d(df_private, x='avg_order_value', y='days_between_trans', z='dog_share', color='cluster')\n",
    "fig.update_layout(width=1600, height=800)\n",
    "fig.update_layout(title='Private Customers - 3D Scatter Plot with Clusters')\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229a3e77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2d19e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899104eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8190282",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccd0e68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5001e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7ebbf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a3e73b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903f8a2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13c0c37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742421f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8c73b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3b3ed1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787c554f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f2a636",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dcfa6f92",
   "metadata": {},
   "source": [
    "### Scaling Features for further Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6f6bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scaling Features\n",
    "# Create a copy of the dataframe\n",
    "df_scaled = df.copy()\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the data\n",
    "df_scaled[['num_transactions', 'total_order_value', 'days_between_trans', 'repeat_share', 'dog_share']] = scaler.fit_transform(df[['num_transactions', 'total_order_value', 'days_between_trans', 'repeat_share', 'dog_share']])\n",
    "df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4294305b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the summary statistics of the scaled data\n",
    "df_scaled.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab4b586",
   "metadata": {},
   "source": [
    "# Clustering and Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0f8d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Try out more Cluster algorithms and see which one fits the best\n",
    "#TODO: Try out more Dimensionality Reduction algorithms and see which one fits the best\n",
    "#TODO: Try to generate more features and see if the model improves\n",
    "#TODO: Try different number of clusters to find a better optimum (Elbow Method or Silhouette Score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7294d08c",
   "metadata": {},
   "source": [
    "We can use a 3 cluster segmentation in which we describe a high quality, medium quality and low quality customer.\n",
    "\n",
    "The high quality customer is a customer that has a high number of transactions, a high total order value, a low days between transactions, a high repeat share and a high dog share.\n",
    "\n",
    "The low and medium quality customer accordingly. We create a lead score for each customer based on the above features and then segment the customers into 3 clusters.\n",
    "\n",
    "We can then adjust our marketing strategy to target the high quality customers more effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730df6ae",
   "metadata": {},
   "source": [
    "## Choosing the Clustering Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109c5424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First try the k-means clustering algorithm\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Create a copy of the final dataframe and drop the CustomerID column\n",
    "df_scaled_cluster = df_scaled.copy().drop('CustomerID', axis=1)\n",
    "\n",
    "# Initialize the KMeans algorithm\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "\n",
    "# Fit the algorithm to the data\n",
    "df_scaled_cluster['Cluster'] = kmeans.fit_predict(df_scaled_cluster)\n",
    "df_scaled_cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e671ef33",
   "metadata": {},
   "source": [
    "# Evaluation of Segments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da0c0da",
   "metadata": {},
   "source": [
    "## Analyzing Cluster Characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911c8481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean of the clusters\n",
    "cluster_stats = df_scaled_cluster.groupby('Cluster').mean()\n",
    "cluster_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf6ba35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of customers in each cluster\n",
    "cluster_size = df_scaled_cluster['Cluster'].value_counts().reset_index()\n",
    "cluster_size.columns = ['Cluster', 'Count']\n",
    "\n",
    "# Calculate the distribution of each cluster\n",
    "cluster_dist = cluster_size['Count'] / cluster_size['Count'].sum()\n",
    "cluster_size['Distribution'] = cluster_dist\n",
    "cluster_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3285893",
   "metadata": {},
   "source": [
    "## Model Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d4dd7a",
   "metadata": {},
   "source": [
    "### Calculating Commonly Used Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8439bf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the silhouette score\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "silhouette_score(df_scaled_cluster.drop('Cluster', axis=1), df_scaled_cluster['Cluster'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b0af46",
   "metadata": {},
   "source": [
    "A score of more than 0.5 indicates a high-quality cluster. In our case it of course depends on the application of our clusters. If we are looking for a small number of high-quality customers, the results indicate that we could have already found them. Lets check the results further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7479924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Davies-Bouldin Index\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "\n",
    "davies_bouldin_score(df_scaled_cluster.drop('Cluster', axis=1), df_scaled_cluster['Cluster'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20644529",
   "metadata": {},
   "source": [
    "### Visualizing the Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14226cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results of the clustering by using the Cluster column and the num_transactions and total_order_value columns\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='repeat_share', y='dog_share', hue='Cluster', data=df_scaled_cluster, palette='viridis')\n",
    "plt.title('KMeans Clustering Results')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e9dac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results of the clustering by using the Cluster column and the num_transactions and total_order_value columns\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='num_transactions', y='total_order_value', hue='Cluster', data=df_scaled_cluster, palette='viridis')\n",
    "plt.title('KMeans Clustering Results')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47cfb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results of the clustering by using the Cluster column and the num_transactions and total_order_value columns\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='total_order_value', y='days_between_trans', hue='Cluster', data=df_scaled_cluster, palette='viridis')\n",
    "plt.title('KMeans Clustering Results')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355068a7",
   "metadata": {},
   "source": [
    "We can clearly see already that the clustering gives us a good segmentation of the customers. It is especially helpful to find the high quality customers that we want to explicitly target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4b8d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the Cluster column to the final dataframe\n",
    "df_final['Cluster'] = df_scaled_cluster['Cluster']\n",
    "\n",
    "# Visualize the cluster plots using PCA\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='PCA1', y='PCA2', hue='Cluster', data=df_final, palette='viridis')\n",
    "plt.title('KMeans Clustering Results with PCA')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1715421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Visualize the cluster plots using t-SNE\n",
    "# from sklearn.manifold import TSNE\n",
    "\n",
    "# # Initialize the t-SNE algorithm\n",
    "# tsne = TSNE(n_components=2, random_state=42)\n",
    "\n",
    "# # Fit and transform the data\n",
    "# df_tsne = tsne.fit_transform(df_scaled_cluster.drop('Cluster', axis=1))\n",
    "\n",
    "# # Create a dataframe with the t-SNE components\n",
    "# df_tsne = pd.DataFrame(data=df_tsne, columns=['t-SNE1', 't-SNE2'])\n",
    "\n",
    "# # Concatenate the t-SNE components with the cluster column\n",
    "# df_tsne = pd.concat([df_tsne, df_scaled_cluster['Cluster']], axis=1)\n",
    "\n",
    "# # Visualize the cluster plots using t-SNE\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# sns.scatterplot(x='t-SNE1', y='t-SNE2', hue='Cluster', data=df_tsne, palette='viridis')\n",
    "# plt.title('KMeans Clustering Results with t-SNE')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0a5a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use plotly to create a 3D scatter plot of the clusters\n",
    "fig = px.scatter_3d(df_scaled_cluster, x='num_transactions', y='total_order_value', z='days_between_trans', color='Cluster', opacity=0.7)\n",
    "fig.update_layout(title='KMeans Clustering Results in 3D')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee68fb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use plotly to create a 3D scatter plot of the clusters\n",
    "fig = px.scatter_3d(df_scaled_cluster, x='num_transactions', y='repeat_share', z='dog_share', color='Cluster', opacity=0.7)\n",
    "fig.update_layout(title='KMeans Clustering Results in 3D')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d850d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use plotly to create a 3D scatter plot of the clusters\n",
    "fig = px.scatter_3d(df_scaled_cluster, x='num_transactions', y='days_between_trans', z='repeat_share', color='Cluster', opacity=0.7)\n",
    "fig.update_layout(title='KMeans Clustering Results in 3D')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884ed219",
   "metadata": {},
   "source": [
    "In this section we closely looked at the clusters and the characteristics of the customers in each cluster. We also validated the model by calculating commonly used scores and visualizing the clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0587ea1f",
   "metadata": {},
   "source": [
    "# Final Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43fcf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge df_scaled['CustomerID'] with df_scaled_cluster['Cluster']\n",
    "df_clustered = pd.concat([df_scaled['CustomerID'], df_scaled_cluster['Cluster']], axis=1)\n",
    "df_clustered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb50a1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the clustered data to a CSV file\n",
    "df_clustered.to_csv('Clustered_Data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2fedc5",
   "metadata": {},
   "source": [
    "# Conclusion and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce315c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Make create a Report that looks professional and is easy to understand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91f5930",
   "metadata": {},
   "source": [
    "## Business Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c15adef",
   "metadata": {},
   "source": [
    "## Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861ce1da",
   "metadata": {},
   "source": [
    "1. Having found the customer segments, it is now the next step to target these different segments in the correct way.\n",
    "2. Offer them simple solutions for each customer segmentation that they can straight away use.\n",
    "3. Sell them a follow up project for a more advanced solution (creating a 'Save the running away customers' by creating a model that can customize the advertisement and special offer)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c7764d",
   "metadata": {},
   "source": [
    "4. With a longer history of at least 2-3 years we can implement a Customer Lifetime Value model which helps to find out which customers to invest in (using PyMC-Marketing library https://github.com/pymc-labs/pymc-marketing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383ea439",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "3fcbd7240ee8f908d933dc7f71e8c42a1a91163b70ede8dcff5146d4087436c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
