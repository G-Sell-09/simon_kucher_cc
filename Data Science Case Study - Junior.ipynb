{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "27f14d9a-8893-449a-930e-f5d946957a2c",
   "metadata": {},
   "source": [
    "# Problem Description\n",
    "***alles um tier GmBH*** is a pet supplies company. They are currently auditing their promotional activities and the CEO, one of the main stakeholders, feels that the promotions they offer is too generic and not targeted. They have requested us to devise a customer segmentation model that they can use to run targeted promotional activities.\n",
    "\n",
    "The client is interested in seeing what kind of customers are buying at ***alles um tier GmbH***. They assume that, in addition to private individuals, there are also smaller companies that purchase from ***alles um tier GmBH***. The project scope is to build a segmentation model and analyze the resulting customer segments.\n",
    "\n",
    "# Data\n",
    "\n",
    "You are given a dataset at customer level for the past year with the following data points. Number of transactions in the past year (*num_transactions*), order amount the past year (*total_order_value*), days between transactions the past year (*days_between_trans*), re-order rate the past year (*repeat_share*), and % of dog products bought (*dog_share*).\n",
    "\n",
    "### Data Set\n",
    "The dataset consists of 100k rows and has the following columns:\n",
    "\n",
    "* CustomerID (int): UUID for the customer\n",
    "* num_transactions (int): number of transactions in a given year\n",
    "* total_order_value (float): total order value in â‚¬ for the time period\n",
    "* days_between_trans (float): average days between transactions for a user\n",
    "* repeat_share (float): product share repeated every order\n",
    "* dog_share (float): percentage of products ordered that are dog food related\n",
    "    \n",
    "# Technical Environment\n",
    "* Python\n",
    "* numpy\n",
    "* pandas\n",
    "* scikit-learn\n",
    "* matplotlib / scipy / searborn / altair / plotly\n",
    "\n",
    "# Approach\n",
    "The solution is assessed on the following skills:\n",
    "* A thorough evaluation of the data set using statistical measures and visualization\n",
    "* Elegant Python coding skills\n",
    "* Machine learning modelling fundamentals\n",
    "* Model & result evaluation\n",
    "\n",
    "# Output\n",
    "Please provide your solution in a jupyter notebook with clear markdown comments.\n",
    "The final output should be in the form of a DataFrame with two columns, the CustomerId and the assigned cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4acb833",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------\n",
    "--------------------------------------------------------------------------------------------------------------\n",
    "--------------------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22559e30",
   "metadata": {},
   "source": [
    "# Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b57f63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all needed libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import altair as alt\n",
    "import plotly.express as px\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f087c59",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed64ab0-ad74-42b4-a516-857d513a1f2e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# load the data and make sure to specify the correct delimiter\n",
    "df = pd.read_csv(\"DataSet_JuniorCodingChallenge.csv\", delimiter='|')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6727eda2",
   "metadata": {},
   "source": [
    "## Handling Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acf5ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how often two values are missing in one row\n",
    "print(f\"Number of rows with two missing values: {len(df[df.isnull().sum(axis=1) == 2])}\")\n",
    "\n",
    "dropping = len(df[df.isnull().sum(axis=1) == 1])/len(df)\n",
    "print(f\"Percentage of rows with one missing value: {dropping:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37eb4ef",
   "metadata": {},
   "source": [
    "On the one hand, we see that only one entry is missing at a time, so it would make sense to fill in these values. On the other hand, only 0.46 % of all customer data have missing values. It could be argued that it is reasonable to simply drop these values, but due to the fact that only one value is missing at a time, we can e.g. use K-Nearest Neighbors Imputation on all numerical values and fill the missing entries in this way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76dbf0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Create a copy and drop the CustomerID column\n",
    "df_knn = df.drop(columns='CustomerID')\n",
    "\n",
    "# Use KNN imputation to fill in the missing values\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "df_imputed = pd.DataFrame(imputer.fit_transform(df_knn), columns=df_knn.columns)\n",
    "\n",
    "# Print a statemetn that len(df_imputed.isnull().sum()) is 0\n",
    "print(f\"Showcasing the missing values after imputation:\\n{df_imputed.isnull().sum()}\")\n",
    "\n",
    "# # Check the newly filled values\n",
    "# missing_indices = df[df.isnull().sum(axis=1) == 1].index\n",
    "# df.loc[missing_indices]\n",
    "# df_imputed.loc[missing_indices]\n",
    "\n",
    "# Print a statement to that the new values were checked and seem reasonable\n",
    "print(\"The new filled entries were double checked again and they are reasonable.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c0f447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Either drop the missing values or use the imputed data\n",
    "df_drop = df.dropna()\n",
    "\n",
    "# Set df to the imputed data and add the CustomerID column back to the first column\n",
    "df = pd.concat([df['CustomerID'], df_imputed], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18558a30",
   "metadata": {},
   "source": [
    "## Data Integrity Check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3431260",
   "metadata": {},
   "source": [
    "At first we want to make sure that the num_transaction has the correct integer values and that the other numerical features are saved as floats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303900ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the current data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73badef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that counts all entries that are not .00 floats\n",
    "def find_floats(df, column):\n",
    "    count = 0\n",
    "    for i in df[column].unique():\n",
    "        if i % 1 != 0:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "# State how many entries need to be rounded in the num_transactions column\n",
    "print(f\"There are {find_floats(df, 'num_transactions')} entries that are not .00 floats and need to be rounded.\")\n",
    "\n",
    "# Round all float values before converting them to integers\n",
    "df['num_transactions'] = df['num_transactions'].apply(lambda x: round(x))\n",
    "\n",
    "# Double Check if all values are rounded now with a print statement\n",
    "print(f\"There are {find_floats(df, 'num_transactions')} entries that are not .00 floats left.\")\n",
    "\n",
    "# Convert num_transactions to integers\n",
    "df['num_transactions'] = df['num_transactions'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9ae8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check all types again\n",
    "print(\"All data types are correct now.\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d755a0",
   "metadata": {},
   "source": [
    "Now we want to make sure that all numerical values are in reasonable ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f84040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of negative values for num_transactions, total_order_value and days_between_trans for negative values\n",
    "print(f\"Number of negative values for num_transactions: {len(df[df['num_transactions'] < 0])}\")\n",
    "print(f\"Number of negative values for total_order_value: {len(df[df['total_order_value'] < 0])}\")\n",
    "print(f\"Number of negative values for days_between_trans: {len(df[df['days_between_trans'] < 0])}\")\n",
    "\n",
    "# Check repeat_share and dog_share for values between 0 and 1. So count the number of values outside of this range\n",
    "print(f\"Number of values outside of the range [0, 1] for repeat_share: {len(df[(df['repeat_share'] < 0) | (df['repeat_share'] > 1)])}\")\n",
    "print(f\"Number of values outside of the range [0, 1] for dog_share: {len(df[(df['dog_share'] < 0) | (df['dog_share'] > 1)])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b596c3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the negative values in the 3 columns\n",
    "df = df[df['num_transactions'] >= 0]\n",
    "df = df[df['total_order_value'] >= 0]\n",
    "df = df[df['days_between_trans'] >= 0]\n",
    "\n",
    "# Drop the values outside of the range 0 and 1 for the last two columns\n",
    "df = df[(df['repeat_share'] >= 0) & (df['repeat_share'] <= 1)]\n",
    "df = df[(df['dog_share'] >= 0) & (df['dog_share'] <= 1)]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b6f55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find duplicates in the CustomerID column and check whether they are consistent\n",
    "def find_inconsistent_duplicates(df, object_col):\n",
    "    # Get the indices of duplicated entries in the object column\n",
    "    duplicated_indices = df[df.duplicated(subset=[object_col], keep=False)].index\n",
    "\n",
    "    # Dictionary to store the indices of inconsistent duplicates\n",
    "    inconsistent_indices = []\n",
    "\n",
    "    # Group by the object column and iterate over each group\n",
    "    for key, group in df.loc[duplicated_indices].groupby(object_col):\n",
    "        # Get the first row's data (excluding the object column)\n",
    "        reference_row = group.iloc[0, 1:].values\n",
    "        \n",
    "        # Check if all rows in the group match the first row\n",
    "        for idx, row in group.iterrows():\n",
    "            if not (row.iloc[1:].values == reference_row).all():\n",
    "                inconsistent_indices.append(idx)\n",
    "\n",
    "    return inconsistent_indices\n",
    "\n",
    "indices_with_inconsistencies = find_inconsistent_duplicates(df, 'CustomerID')\n",
    "\n",
    "# Print the number of inconsistent duplicates\n",
    "print(f\"Number of inconsistent duplicates: {len(indices_with_inconsistencies)}. This is why we can simply drop one of them.\")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0564692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# State how many CustomerIDs are duplicated and that they will be dropped\n",
    "print(f\"There are {df['CustomerID'].duplicated().sum()} duplicated CustomerIDs. They will be dropped.\")\n",
    "\n",
    "# Drop the duplicated CustomerIDs\n",
    "df = df.drop_duplicates(subset='CustomerID')\n",
    "\n",
    "# Reset the index\n",
    "df = df.reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1cdf69",
   "metadata": {},
   "source": [
    "In this section, we first loaded the data and then checked for missing values and filled them using K-Nearest Neighbors Imputation. We then checked for data integrity by looking at the data types of the columns, at the reasonable ranges of the data and the unique CustomerIDs.\n",
    "\n",
    "Now the data is ready for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d259363",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis **(EDA)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8c206e",
   "metadata": {},
   "source": [
    "## Statistical Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fe4cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary statistics for the data\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a377d6d1",
   "metadata": {},
   "source": [
    "Using the describe() function, we obtained a detailed overview of each variable, including key statistics such as mean, standard deviation, and quartiles. This provided an initial understanding of the distribution of the features and highlighted the presence of potential outliers, which were explored further in the subsequent visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735c4298",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7eb26f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a histogram for each column\n",
    "df.hist(figsize=(10, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4895a8e4",
   "metadata": {},
   "source": [
    "The histograms of all numerical variables revealed varying distributions across features, with some exhibiting skewness. For example, num_transactions and total_order_value are skewed to the right, indicating the presence of a few customers with a high volume of transactions or large order values. This may support the CEO's hypothesis that there are also corporate customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f08d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.drop(columns='CustomerID')\n",
    "\n",
    "# Creating multiple boxplots, one for each column\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i, col in enumerate(df_copy.columns):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    sns.boxplot(x=df_copy[col])\n",
    "    plt.title(col)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fcdab2",
   "metadata": {},
   "source": [
    "The boxplots further reinforced the hypothesis by highlighting significant outliers, particularly in total_order_value and days_between_trans. These extreme values likely represent corporate customers, who order infrequently but in large volumes. Understanding the spread and identifying outliers is crucial for later feature engineering and clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876cbbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a correlation matrix and visualize it with a heatmap\n",
    "corr = df_copy.corr()\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca1824a",
   "metadata": {},
   "source": [
    "The correlation matrix provided valuable insights into the relationships between features:\n",
    "\n",
    "* days_between_trans and repeat_share (-0.67): This negative linear correlation suggests that customers with higher reordering rates tend to have shorter intervals between purchases. These could be customers who place routine, frequent orders, possibly on a weekly or monthly basis.\n",
    "\n",
    "* days_between_trans and dog_share (0.41): The positive correlation indicates that customers who order less frequently tend to have a higher share of dog-related products in their purchases. However, this relationship requires further exploration as it could indicate differing customer types (e.g., occasional buyers focused on specific products like dog food)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454cff72",
   "metadata": {},
   "source": [
    "## Feature Relationships and Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5c426d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating pairplots for all numerical data\n",
    "sns.pairplot(df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb05525",
   "metadata": {},
   "source": [
    "The pairplot helped visualize the relationships between all features:\n",
    "\n",
    "* num_transactions vs. total_order_value: This relationship highlights two distinct customer behaviors. Frequent, smaller orders could suggest private customers who need regular household supplies, while infrequent but large orders could represent smaller companies making bulk purchases. This supports the hypothesis of different customer segments: private individuals versus corporate clients.\n",
    "\n",
    "* num_transactions & days_between_trans vs. repeat_share: The plots suggest three distinct customer segments. Two noticeable clusters of private customers (those making regular, repeated purchases) are evident, as well as a group of outliers, likely representing corporate clients. The corporate clients typically have fewer transactions but higher order volumes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86424959",
   "metadata": {},
   "source": [
    "### Dropping some of the Outliers in a 1st Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba0fe0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 10% outliers from the data in a new copy\n",
    "df_no_outliers = df.copy()\n",
    "\n",
    "# Define the columns to check for outliers\n",
    "columns = ['num_transactions', 'total_order_value', 'days_between_trans', 'repeat_share', 'dog_share']\n",
    "\n",
    "# Iterate over the columns and remove the outliers\n",
    "for col in columns:\n",
    "    # Calculate the z-scores for each value in the column\n",
    "    z_scores = np.abs(stats.zscore(df_no_outliers[col]))\n",
    "\n",
    "    # 99.9% confidence interval (2194 outliers)\n",
    "    outlier_indices = np.where(z_scores > 3.291)[0]\n",
    "\n",
    "    # 99.5% confidence interval (3523 outliers)\n",
    "    # outlier_indices = np.where(z_scores > 2.807)[0]\n",
    "\n",
    "    # 99% confidence interval (4532 outliers)\n",
    "    # outlier_indices = np.where(z_scores > 2.58)[0]\n",
    "\n",
    "    # 95% confidence interval (17560 outliers)\n",
    "    # outlier_indices = np.where(z_scores > 1.96)[0] \n",
    "\n",
    "    # 90% confidence interval (29567 outliers)\n",
    "    # outlier_indices = np.where(z_scores > 1.64)[0]\n",
    "\n",
    "    # Drop the outliers\n",
    "    df_no_outliers = df_no_outliers.drop(index=outlier_indices)\n",
    "\n",
    "    # Reset the index\n",
    "    df_no_outliers = df_no_outliers.reset_index(drop=True)\n",
    "\n",
    "# How many outliers were removed\n",
    "print(f\"{len(df) - len(df_no_outliers)} outliers were removed.\")\n",
    "\n",
    "# Visualize the pairplots for the data without outliers\n",
    "sns.pairplot(df_no_outliers)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36c583b",
   "metadata": {},
   "source": [
    "After removing outliers using a 99.9% confidence interval, we gained clearer insights into the private customer segments:\n",
    "\n",
    "* total_order_value vs. num_transactions: There is now a distinct relationship between higher total order values and increased transaction frequency. Customers who frequently place orders also tend to reorder the same products, suggesting a routine purchasing behavior.\n",
    "\n",
    "* Customer Segments: Two key customer segments are visible:\n",
    "    1. Low-frequency, low-volume buyers: These customers tend to have a high number of days between transactions and low repeat orders. They may represent trial users who were not fully convinced by the product offerings and could be targeted with win-back strategies (e.g., special offers or discounts).\n",
    "    2. High-frequency, high-volume buyers: These customers order frequently and tend to reorder the same products. They likely have a stable shopping pattern, making them ideal candidates for loyalty programs or early access to new products.\n",
    "\n",
    "* Repeat Share vs. Days Between Transactions: A clear segmentation emerges here. Customers with short intervals between transactions tend to have higher repeat share percentages, indicating they rely on certain staple products. On the other hand, less frequent buyers have lower repeat shares, suggesting they might experiment with different products. This insight could be useful for targeted promotions focusing on new or complementary products for loyal customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be4e9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix for the data without outliers\n",
    "corr_no_outliers = df_no_outliers.drop(columns='CustomerID').corr()\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(corr_no_outliers, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix without Outliers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e7e464",
   "metadata": {},
   "source": [
    "After removing the outliers, the correlation matrix further validated several key relationships:\n",
    "\n",
    "* num_transactions and total_order_value (0.98): This strong positive correlation highlights that frequent buyers naturally accumulate higher total order values over time. This relationship is particularly relevant for private customers, who tend to make smaller, frequent purchases.\n",
    "\n",
    "* days_between_trans and other features: The negative correlations between days_between_trans and both num_transactions (-0.84) and total_order_value (-0.79) emphasize that customers who order more frequently tend to have shorter gaps between transactions. This is expected and supports the segmentation of frequent buyers with routine purchasing behaviors.\n",
    "\n",
    "* repeat_share vs. days_between_trans (-0.8): The negative correlation between the repeat order rate and days between transactions further indicates that customers with shorter transaction intervals tend to reorder the same products. These insights could inform the development of targeted promotions that focus on encouraging product trials or cross-selling to customers who rely on routine purchases.\n",
    "\n",
    "* dog_share vs. num_transactions (-0.38): The inverse relationship here suggests that customers who place frequent orders tend to have a lower percentage of dog-related products. This is an important insight for product targeting, as infrequent buyers are more likely to be interested in dog-related products, whereas frequent buyers diversify their purchases beyond pet supplies (especially dog supplies)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b9a1c2",
   "metadata": {},
   "source": [
    "### Creating a new Feature â€“ avg_order_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9a1271",
   "metadata": {},
   "source": [
    "* Given the high correlation between total_order_value and num_transactions (0.98), we derived a new feature, avg_order_value, to represent the average value of each order per customer. This transformation simplifies the analysis by consolidating these two highly correlated features into a more interpretable metric.\n",
    "\n",
    "* Calculating the average order value provides a clearer insight into how much a customer spends per transaction, removing the noise of transaction frequency. This newly engineered feature will help in better understanding the purchasing behavior of different customer segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a576ed2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Due to the very high linear correlation between num_transactions and total_order_value, we create a combined feature\n",
    "# that represents the average order value per transaction\n",
    "df_no_outliers['avg_order_value'] = df_no_outliers['total_order_value'] / df_no_outliers['num_transactions']\n",
    "\n",
    "# Set the new column as the first column and drop the old columns\n",
    "df_no_outliers = df_no_outliers[['CustomerID', 'avg_order_value', 'days_between_trans', 'repeat_share', 'dog_share']]\n",
    "\n",
    "\n",
    "# ALso do this for the original data\n",
    "df['avg_order_value'] = df['total_order_value'] / df['num_transactions']\n",
    "# df = df[['CustomerID', 'avg_order_value', 'days_between_trans', 'repeat_share', 'dog_share']]\n",
    "\n",
    "# Check the new data\n",
    "df_no_outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba88adb5",
   "metadata": {},
   "source": [
    "### Visualizing the Dataset with new Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afda8c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use .describe but only for the new feature\n",
    "df_no_outliers['avg_order_value'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbca76f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pairplot that only shows the relationship of the new feature with the other features\n",
    "sns.pairplot(df_no_outliers, y_vars='avg_order_value', x_vars=['days_between_trans', 'repeat_share', 'dog_share'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99f752a",
   "metadata": {},
   "source": [
    "* avg_order_value vs. days_between_trans: Customers who order more frequently (i.e., have lower days_between_trans) tend to have higher average order values. This relationship could indicate that frequent buyers are consistently purchasing higher quantities or more expensive products in each order.\n",
    "\n",
    "* avg_order_value vs. repeat_share: A clear linear relationship is visible here. The higher the average order value, the greater the percentage of repeat items in each order. This suggests that customers with larger average purchases are more likely to reorder the same products regularly, indicating loyalty to specific products.\n",
    "\n",
    "* avg_order_value vs. dog_share: The relationship between these two features is less pronounced. However, there is a slight tendency indicating that customers with lower average order values might have a higher percentage of dog-related products. This could hint at occasional or first-time buyers focused on specific pet-related needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12022b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the correlation only for the new feature with the other features\n",
    "corr_avg_order = df_no_outliers.drop(columns='CustomerID').corr()['avg_order_value']\n",
    "corr_avg_order = corr_avg_order.drop('avg_order_value')\n",
    "\n",
    "# Visualize these findings in a nicer way\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=corr_avg_order.values, y=corr_avg_order.index, palette='coolwarm', hue=corr_avg_order.values)\n",
    "plt.title('Correlation of Average Order Value with the other Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c2c72c",
   "metadata": {},
   "source": [
    "The correlations between the new feature avg_order_value and the remaining features provide further support for the patterns observed in the pairplot:\n",
    "\n",
    "* days_between_trans (-0.78): The negative correlation suggests that customers with shorter intervals between transactions tend to have higher average order values. This is consistent with the idea that frequent buyers make larger or more valuable purchases per transaction.\n",
    "\n",
    "* repeat_share (0.86): The strong positive correlation shows a clear and significant relationship between average order value and the percentage of repeat items in each order. Customers with higher average order values are more likely to reorder the same products regularly, which indicates loyalty and possibly a reliance on staple products. This also implies that high-value customers may be ideal targets for promotions involving new products, as they already exhibit strong purchasing habits.\n",
    "\n",
    "* dog_share (-0.40): The negative correlation between avg_order_value and dog_share suggests that customers with higher average order values tend to have a lower percentage of dog-related products in their orders. This supports the observation that occasional buyers, particularly those with smaller average order values, may be focusing more on dog-related items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ae7595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only visualize the avg_order_value column in a boxplot, but make two plots left and right.\n",
    "# One plot with the original data and one without the outliers\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.boxplot(x=df['avg_order_value'])\n",
    "plt.title('Original Data')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(x=df_no_outliers['avg_order_value'])\n",
    "plt.title('Data without Outliers')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6c2e91",
   "metadata": {},
   "source": [
    "* Full Dataset: The left boxplot, which includes the entire dataset, clearly highlights the presence of corporate customers with significantly higher average order values. These outliers, representing large, less frequent purchases, are distinct from the general population of private customers. This visual representation reinforces the need to segment these corporate customers for more targeted analysis later on.\n",
    "\n",
    "* Outlier-Free Dataset: The right boxplot, after removing outliers, provides a more refined view of the average order value distribution among private customers. It shows a narrower range, giving a clearer sense of the central tendency and spread of average order values. Most regular customers have average order values clustered within a range of 14 to 25 euros, confirming that corporate customers were skewing the previous analysis.\n",
    "\n",
    "This refined understanding of avg_order_value sets the stage for the next analysis, where corporate customers will be more precisely identified and characterized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f9813f",
   "metadata": {},
   "source": [
    "### Finding the Corporate Customers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09aa443",
   "metadata": {},
   "source": [
    "Now that we have a more robust understanding of the data and the newly created feature, we can use that feature to filter out more precisely the corporate customers. We are therefore first using a classic approach to identify outliers, the Initerquartile Range. Afterwards we will by hand look for a precise boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb811f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is obvious that the avg_order_value column has a lot of outliers. What is the best way to identify how many outliers there are?\n",
    "# We can use the IQR method to identify the outliers in the avg_order_value column\n",
    "Q1 = df['avg_order_value'].quantile(0.25)\n",
    "Q3 = df['avg_order_value'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Calculate the number of outliers\n",
    "outliers = df[(df['avg_order_value'] < (Q1 - 1.5 * IQR)) | (df['avg_order_value'] > (Q3 + 1.5 * IQR))]\n",
    "print(f\"Number of outliers in the avg_order_value column: {len(outliers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87599a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the original data and rank the dataset by the avg_order_value column in descending order\n",
    "df_ranked = df.sort_values(by='avg_order_value', ascending=False).reset_index(drop=True)\n",
    "df_ranked.head(len(outliers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f517206",
   "metadata": {},
   "source": [
    "We can see a very clear boundary in regard of the avg_order_value at index 95 where we have an avg_order_value of 2370 euro and the next customer of only 96.50 euro. This means that we have reason enough to believe that the corporates were found. Interestingly, we can also see that the following customer, tvs855 has a significant lower average order value of 96.50 euro but in total order value is on the same level as the last previously identified corporates. We will therefore now also look at the total order value again and use the same technique to find the outliers in that regard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a810aea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is obvious that the avg_order_value column has a lot of outliers. What is the best way to identify how many outliers there are?\n",
    "# We can use the IQR method to identify the outliers in the avg_order_value column\n",
    "Q1 = df['total_order_value'].quantile(0.25)\n",
    "Q3 = df['total_order_value'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Calculate the number of outliers\n",
    "outliers = df[(df['total_order_value'] < (Q1 - 1.5 * IQR)) | (df['total_order_value'] > (Q3 + 1.5 * IQR))]\n",
    "print(f\"Number of outliers in the total_order_value column: {len(outliers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7e021a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now rank the df by the total order value\n",
    "df_ranked_total = df.sort_values(by='total_order_value', ascending=False).reset_index(drop=True)\n",
    "df_ranked_total.iloc[1580:1595]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc8ea18",
   "metadata": {},
   "source": [
    "Here again we can see a clear boundary at index 1586 in which we have a total order value of 6726 euro. The next ranked customer only has a total order value of 658 euro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553aefed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ranked_total.iloc[92:107]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c1ad86",
   "metadata": {},
   "source": [
    "We now realized that there is another cluster in the dataset of companies with a high total order value and a very low days between transactions value, meaning they order with a very high frequency almost daily or every second day, as well as in an overall order value that is not classical for a private customer. Therefore these seem to be another category of corporate customers that order with a high frequency.\n",
    "\n",
    "In this dataset we can see an outlier when it comes to days_between_trans. This seems to be a clear data error that will be corrected now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86803f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WIthin df_ranked_total.iloc[:1595] check for customers that have a days_between_trans value of above 5\n",
    "df_ranked_total.iloc[97:1587][df_ranked_total.iloc[97:1587]['days_between_trans'] > 5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd500044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the df_ranked_total from 96 to 1586 and plot the days_between_trans column in a boxplot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=df[df['num_transactions'] == 401]['days_between_trans'][df[df['num_transactions'] == 401 ]['days_between_trans'] < 1000])\n",
    "plt.title('Boxplot of the days_between_trans column for the first 1587 companies of total_order_value')\n",
    "plt.show()\n",
    "\n",
    "# Calculate the mean of that column for that range\n",
    "print(f\"The mean of the days_between_trans column for the first 1587 companies of total_order_value is {df[df['num_transactions'] == 401]['days_between_trans'][df[df['num_transactions'] == 401]['days_between_trans'] < 1000].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5c25f4",
   "metadata": {},
   "source": [
    "We can see the range in which this segment of customers are in including the exact average value. This drives us to a reasonable assumption that the value was maybe saved by an error of 3 digits, meaning we need to divide it by 1000 to further work with it. That is being done in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43f08a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct the value of the company with the index 1228\n",
    "# df_ranked_total.loc[1228, 'days_between_trans'] = df_ranked_total.loc[1228, 'days_between_trans'] / 1000\n",
    "df_ranked_total.loc[957, 'days_between_trans'] = df_ranked_total.loc[957, 'days_between_trans'] / 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b1bf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ranked_total.iloc[97:1587][df_ranked_total.iloc[97:1587]['days_between_trans'] > 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56259cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ranked_total.iloc[97:1587][df_ranked_total.iloc[97:1587]['days_between_trans'] < 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043b59de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168fe1d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b456913e",
   "metadata": {},
   "source": [
    "Here we can now clearly see a boundary and it seems more than reasonable to cut the dataset into the first 96 customers and then the rest which we from now on will assume to be private customers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cf8544",
   "metadata": {},
   "source": [
    "### Dividing the Dataset into Corporate and Private Customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacdfe9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the corporate custome datarframe by using only the first 96 rows\n",
    "df_corporate = df_ranked.head(96)\n",
    "df_corporate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63cc954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the private customer dataframe by using the remaining rows\n",
    "df_private = df_ranked.iloc[96:]\n",
    "df_private = df_private.reset_index(drop=True)\n",
    "df_private"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa59e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))  # Adjust the figure size for four plots\n",
    "\n",
    "# First row: Boxplots\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.boxplot(x=df_corporate['avg_order_value'])\n",
    "plt.title('Corporate Customers - Boxplot')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.boxplot(x=df_private['avg_order_value'])\n",
    "plt.title('Private Customers - Boxplot')\n",
    "\n",
    "# Second row: Histograms\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.histplot(df_corporate['avg_order_value'], bins=20)\n",
    "plt.title('Corporate Customers - Histogram')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.histplot(df_private['avg_order_value'], bins=20)\n",
    "plt.title('Private Customers - Histogram')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66aa0c5a",
   "metadata": {},
   "source": [
    "Having the dataset split into two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb2d311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the correlation matrix for the corporate customers in a plot with two plots on the left, and on the right the private customers\n",
    "plt.figure(figsize=(24, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.heatmap(df_corporate.drop(columns=['CustomerID', 'total_order_value','num_transactions']).corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix - Corporate Customers')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.heatmap(df_private.drop(columns=['CustomerID', 'total_order_value','num_transactions']).corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix - Private Customers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d121a9d",
   "metadata": {},
   "source": [
    "We are now able to analyse each customer segmentation in a more precisey way. We can already see clear differences.\n",
    "\n",
    "Corporate Customers:\n",
    "\n",
    "On the left hand side the corporate customers, which order less frequent the higher their average order value was - something that makes absolute sense. Then we can also see that the customers who more frequently order also have a higher repeating order share. This again makes sense as they are running out of specific product more quickly (as they also order less on average due to the first finding) and therefore need the same products more often. Lastly the dog related food products in each order. There seems to be a slight higher dog related food order for companies with a higher average order value. This feature should be more closely analyzed afterwards.\n",
    "\n",
    "\n",
    "Private Customers:\n",
    "\n",
    "On the right hand side the private customers, where we can see a very different behaviour when it comes to the average order value and the days between transactions. It seems that the higher the average order value, the more frequently the customer orders. It seems reasonable to make the hypothesis that we can divide the customer side into high-spending frequent buyers and low-spending infrequent buyers once again. This is also supported by the strong linear relationship of the average order value and the repeating share. It seems like the high-spending frequent buyers also order the same products very often. Interestingly, different to the corporate customers, the higher spending customers on average buy less dog food related products. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f41b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the corporate customers in a 3d scatter plot using the average order value, the days between transactions and the dog share, but color the points by the repeat share\n",
    "fig = px.scatter_3d(df_corporate, x='avg_order_value', y='days_between_trans', z='dog_share', color='repeat_share')\n",
    "\n",
    "# Set the size of the figure\n",
    "fig.update_layout(width=1600, height=800)\n",
    "\n",
    "fig.update_layout(title='Corporate Customers - 3D Scatter Plot')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb54db5",
   "metadata": {},
   "source": [
    "With this plot we already get a good feeling of the rather small dataset of corporate customers. From more frequently ordering corporates with rather low average order value and a fairly equally distributed dog food related share (from about 3 to 50%) to the less frequent, but therefore rather higher per order spending corporates with a not distinctly seperatable dog share percentage. There is one high spending per order corporate with a really high dog share of about 62%, but also one with only 8%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d54b605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now the same for the private customers\n",
    "fig = px.scatter_3d(df_private, x='avg_order_value', y='days_between_trans', z='dog_share', color='repeat_share')\n",
    "\n",
    "# Set the size of the figure\n",
    "fig.update_layout(width=1600, height=800)\n",
    "\n",
    "fig.update_layout(title='Private Customers - 3D Scatter Plot')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9a1e11",
   "metadata": {},
   "source": [
    "In this plot we can see that there are some weird looking data points with days of more than 364 in between transactions. Due to the knowledge of a given data set of the last year this has to be an error. Something we should look at more closely next.\n",
    "\n",
    "Also there is one very interesting customer with a very high dog share percentage and a really high average order value that seems to order every two days. This customer should be analyzed separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494e2130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out the private customers that have a days_between_trans value of higher than 364 (the maximum)\n",
    "df_private_hd = df_private[df_private['days_between_trans'] > 364]\n",
    "\n",
    "# Visualize the private customers with a days_between_trans of more than 364 days in a 3d scatter plot\n",
    "fig = px.scatter_3d(df_private_hd, x='avg_order_value', y='days_between_trans', z='dog_share', color='repeat_share')\n",
    "\n",
    "# Set the size of the figure\n",
    "fig.update_layout(width=1600, height=800)\n",
    "\n",
    "fig.update_layout(title='Private Customers with more than 364 days between transactions - 3D Scatter Plot')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5a1164",
   "metadata": {},
   "source": [
    "Except for their off looking number of days between transactions the data seems to be reasonable. Therefore we will simply set the number of days_between_transaction to a reasonable value. We will therefore have a closer look at the most outstanding data points in that regard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12a500d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the private customers again with the 3d scatter plot but without the customers that have more than 364 days between transactions\n",
    "fig = px.scatter_3d(df_private[df_private['days_between_trans'] <= 364], x='avg_order_value', y='days_between_trans', z='dog_share', color='repeat_share')\n",
    "fig.update_layout(width=1600, height=800)\n",
    "fig.update_layout(title='Private Customers - 3D Scatter Plot')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dec809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the number of customers that have a days_between\n",
    "print(f\"Number of private customers that have more than 364 days between transactions: {len(df_private[df_private['days_between_trans'] > 364])}\")\n",
    "print(f\"Number of private customers that have more than 240 days between transactions: {len(df_private[df_private['days_between_trans'] > 240])}\")\n",
    "print(f\"Number of private customers that have more than 236 days between transactions: {len(df_private[df_private['days_between_trans'] > 236])}\")\n",
    "print(f\"Number of private customers that have more than 235 days between transactions: {len(df_private[df_private['days_between_trans'] > 235])}\")\n",
    "print(f\"Number of private customers that have more than 234 days between transactions: {len(df_private[df_private['days_between_trans'] > 234])}\")\n",
    "print(f\"Number of private customers that have more than 233 days between transactions: {len(df_private[df_private['days_between_trans'] > 233])}\")\n",
    "print(f\"Number of private customers that have more than 1000 days between transactions: {len(df_private[df_private['days_between_trans'] > 1000])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8777dfd3",
   "metadata": {},
   "source": [
    "Looking at these numbers, the previous plot and having in mind the total size of the private customer data set it seems reasonable to either set the boundary at 235 or 236. Moving on we will set all values above 235 to the value of 235, so that later segmentations can be done more usefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8512b623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of days between transactions to 235 for the private customers that have more than 235 days\n",
    "df_private.loc[df_private['days_between_trans'] > 235, 'days_between_trans'] = 235\n",
    "\n",
    "# Visualize the private customers again with the 3d scatter plot\n",
    "fig = px.scatter_3d(df_private, x='avg_order_value', y='days_between_trans', z='dog_share', color='repeat_share')\n",
    "\n",
    "# Set the size of the figure\n",
    "fig.update_layout(width=1600, height=800)\n",
    "\n",
    "fig.update_layout(title='Private Customers - 3D Scatter Plot')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229cd24d",
   "metadata": {},
   "source": [
    "Now this plot gives us a great inside into how the private customer data set is distributed and we can already see 3 different segments of customers. For now there are still 3 customers that stand out. They have a high average order value and order about every second day with a very high repeating share of products. We will filter them out specifically now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094bf822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out the private customers with a higher average order value of 40\n",
    "df_private_hao = df_private[df_private['avg_order_value'] > 40]\n",
    "df_private_hao"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc1c6e8",
   "metadata": {},
   "source": [
    "These 3 customers should be contacted with a individual marketing strategy. We will drop them out of the continuing data set and come back to them at the end when recommending a marketing strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e8161f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the df_private_hao from the df_private dataframe\n",
    "df_private = df_private[df_private['avg_order_value'] <= 40]\n",
    "\n",
    "# Visualize the private customers again with the 3d scatter plot\n",
    "fig = px.scatter_3d(df_private, x='avg_order_value', y='days_between_trans', z='dog_share', color='repeat_share')\n",
    "\n",
    "# Set the size of the figure\n",
    "fig.update_layout(width=1600, height=800)\n",
    "\n",
    "fig.update_layout(title='Private Customers - 3D Scatter Plot')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96f3b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter all customers that have a days_between_trans of 235 and average oder value of above 20 and a repeat share of above 0.6\n",
    "df_private_filtered = df_private[(df_private['days_between_trans'] == 235) & (df_private['avg_order_value'] > 20) & (df_private['repeat_share'] > 0.6)]\n",
    "df_private_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729897db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check both the CustomerID in the original data\n",
    "df[df['CustomerID'].isin(df_private_filtered['CustomerID'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83739d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check both the CustomerID in the original data\n",
    "df_private[df_private['CustomerID'].isin(df_private_filtered['CustomerID'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34dd5db",
   "metadata": {},
   "source": [
    "Seeing these two customers in the data set it seems more reasonable that the commata was set in the wrong way and that both these customers rather have about 2.3 days in between each transaction. Therefore we will change their value accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52cccbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the df_private dataframe we will change the days_between_trans value to the value in the df dataframe, but we move the commata 3 values to the left\n",
    "df_private.loc[df_private['CustomerID'].isin(df_private_filtered['CustomerID']), 'days_between_trans'] = df.loc[df['CustomerID'].isin(df_private_filtered['CustomerID']), 'days_between_trans'].values / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f966ae5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the private customers again with the 3d scatter plot\n",
    "fig = px.scatter_3d(df_private, x='avg_order_value', y='days_between_trans', z='dog_share', color='repeat_share')\n",
    "\n",
    "# Set the size of the figure\n",
    "fig.update_layout(width=1600, height=800)\n",
    "\n",
    "fig.update_layout(title='Private Customers - 3D Scatter Plot')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339d48c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframes to csv files\n",
    "df_corporate.to_csv('corporate_customers.csv', index=False)\n",
    "df_private.to_csv('private_customers.csv', index=False)\n",
    "df.to_csv('cleaned_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68500046",
   "metadata": {},
   "source": [
    "Now our data sets and features are finally prepared. In the followoing we will precisely analyse the clusters and do a segmentation analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad09f47",
   "metadata": {},
   "source": [
    "# Clustering and Semntation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8d3e0f",
   "metadata": {},
   "source": [
    "What was done so far:\n",
    "...\n",
    "\n",
    "What we want to do next:\n",
    "...\n",
    "\n",
    "Where we want to end at the end:\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707ef3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load both dataframes again\n",
    "df_corporate = pd.read_csv('corporate_customers.csv')\n",
    "df_private = pd.read_csv('private_customers.csv')\n",
    "df = pd.read_csv('cleaned_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8765b3d6",
   "metadata": {},
   "source": [
    "## Corporate Customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d86c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the corporate customers\n",
    "fig = px.scatter_3d(df_corporate, x='avg_order_value', y='days_between_trans', z='dog_share', color='repeat_share')\n",
    "\n",
    "# Set the size of the figure\n",
    "fig.update_layout(width=1600, height=800)\n",
    "\n",
    "fig.update_layout(title='Corporate Customers - 3D Scatter Plot')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3aa20ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the corporate customers\n",
    "fig = px.scatter_3d(df_corporate, x='total_order_value', y='days_between_trans', z='dog_share', color='repeat_share')\n",
    "\n",
    "# Set the size of the figure\n",
    "fig.update_layout(width=1600, height=800)\n",
    "\n",
    "fig.update_layout(title='Corporate Customers - 3D Scatter Plot')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d3f6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_corporate create a copy of the dataframe and rank it by the column total_order_value\n",
    "df_corporate_ranked = df_corporate.sort_values(by='total_order_value', ascending=False).reset_index(drop=True)\n",
    "df_corporate_ranked.iloc[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb65b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corporate_ranked.iloc[40:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0962db08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use k-means clustering to cluster the corporate customers into two groups\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Create a copy of the corporate customers dataframe\n",
    "df_corporate_cluster = df_corporate.copy()\n",
    "\n",
    "# Drop the CustomerID column, the total_order_value column and the num_transactions column\n",
    "df_corporate_cluster = df_corporate_cluster.drop(columns=['CustomerID', 'total_order_value', 'num_transactions'])\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the data\n",
    "df_corporate_cluster_scaled = scaler.fit_transform(df_corporate_cluster)\n",
    "\n",
    "# Create the KMeans model with 2 clusters\n",
    "kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "kmeans.fit(df_corporate_cluster_scaled)\n",
    "\n",
    "# Add the cluster labels to the dataframe\n",
    "df_corporate['cluster'] = kmeans.labels_\n",
    "\n",
    "# Visualize the clusters in a 3D scatter plot\n",
    "fig = px.scatter_3d(df_corporate, x='avg_order_value', y='days_between_trans', z='dog_share', color='cluster')\n",
    "fig.update_layout(width=1600, height=800)\n",
    "fig.update_layout(title='Corporate Customers - 3D Scatter Plot with Clusters')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749b6fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use k-means clustering to cluster the corporate customers into two groups\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Create a copy of the corporate customers dataframe\n",
    "df_corporate_cluster = df_corporate.copy()\n",
    "\n",
    "# Drop the CustomerID column, the total_order_value column and the num_transactions column\n",
    "df_corporate_cluster = df_corporate_cluster.drop(columns=['CustomerID', 'avg_order_value', 'num_transactions'])\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the data\n",
    "df_corporate_cluster_scaled = scaler.fit_transform(df_corporate_cluster)\n",
    "\n",
    "# Create the KMeans model with 2 clusters\n",
    "kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "kmeans.fit(df_corporate_cluster_scaled)\n",
    "\n",
    "# Add the cluster labels to the dataframe\n",
    "df_corporate['cluster'] = kmeans.labels_\n",
    "\n",
    "# Visualize the clusters in a 3D scatter plot\n",
    "fig = px.scatter_3d(df_corporate, x='total_order_value', y='days_between_trans', z='dog_share', color='cluster')\n",
    "fig.update_layout(width=1600, height=800)\n",
    "fig.update_layout(title='Corporate Customers - 3D Scatter Plot with Clusters')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5993b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use k-means clustering to cluster the corporate customers into two groups\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Create a copy of the corporate customers dataframe\n",
    "df_corporate_cluster = df_corporate.copy()\n",
    "\n",
    "# Drop the CustomerID column, the total_order_value column and the num_transactions column\n",
    "df_corporate_cluster = df_corporate_cluster.drop(columns=['CustomerID', 'total_order_value', 'num_transactions'])\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the data\n",
    "df_corporate_cluster_scaled = scaler.fit_transform(df_corporate_cluster)\n",
    "\n",
    "# Create the KMeans model with 3 clusters\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "kmeans.fit(df_corporate_cluster_scaled)\n",
    "\n",
    "# Add the cluster labels to the dataframe\n",
    "df_corporate['cluster'] = kmeans.labels_\n",
    "\n",
    "# Visualize the clusters in a 3D scatter plot\n",
    "fig = px.scatter_3d(df_corporate, x='avg_order_value', y='days_between_trans', z='dog_share', color='cluster')\n",
    "fig.update_layout(width=1600, height=800)\n",
    "fig.update_layout(title='Corporate Customers - 3D Scatter Plot with Clusters')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e1870a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use k-means clustering to cluster the corporate customers into two groups\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Create a copy of the corporate customers dataframe\n",
    "df_corporate_cluster = df_corporate.copy()\n",
    "\n",
    "# Drop the CustomerID column, the total_order_value column and the num_transactions column\n",
    "df_corporate_cluster = df_corporate_cluster.drop(columns=['CustomerID', 'avg_order_value', 'num_transactions'])\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the data\n",
    "df_corporate_cluster_scaled = scaler.fit_transform(df_corporate_cluster)\n",
    "\n",
    "# Create the KMeans model with 3 clusters\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "kmeans.fit(df_corporate_cluster_scaled)\n",
    "\n",
    "# Add the cluster labels to the dataframe\n",
    "df_corporate['cluster'] = kmeans.labels_\n",
    "\n",
    "# Visualize the clusters in a 3D scatter plot\n",
    "fig = px.scatter_3d(df_corporate, x='total_order_value', y='days_between_trans', z='dog_share', color='cluster')\n",
    "fig.update_layout(width=1600, height=800)\n",
    "fig.update_layout(title='Corporate Customers - 3D Scatter Plot with Clusters')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c54e0d6",
   "metadata": {},
   "source": [
    "The k-means algorithm helps to get an understanding how on the used metric we can split this data set. In regard of our marketing strategies, it seems like is a different approach more applicable. Especially because we are talking about only 96 corporate customers, it makes sense to use a rather by hand approach. Here it makes sense to divide the corporate customers into a matrix total order value and the number of transactions on the side, once categorized to high and low. The boundary is simply set by using the average of each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabf9571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Create a copy of the corporate customers dataframe\n",
    "df_corporate_split = df_corporate.copy()\n",
    "\n",
    "# Calculate the mean for total_order_value and num_transactions\n",
    "mean_total_order_value = df_corporate_split['total_order_value'].mean()\n",
    "mean_num_transactions = df_corporate_split['num_transactions'].mean()\n",
    "\n",
    "# Split based on whether the values are above or below the mean\n",
    "df_corporate_split['total_order_value_split'] = df_corporate_split['total_order_value'].apply(\n",
    "    lambda x: 'low' if x < mean_total_order_value else 'high'\n",
    ")\n",
    "\n",
    "df_corporate_split['num_transactions_split'] = df_corporate_split['num_transactions'].apply(\n",
    "    lambda x: 'low' if x < mean_num_transactions else 'high'\n",
    ")\n",
    "\n",
    "# Combine the two splits into a single group variable for four distinct categories\n",
    "df_corporate_split['group'] = (\n",
    "    df_corporate_split['total_order_value_split'].astype(str) + '_' +\n",
    "    df_corporate_split['num_transactions_split'].astype(str)\n",
    ")\n",
    "\n",
    "# Visualize the 2x2 grid in a 3D scatter plot with four different colors\n",
    "fig = px.scatter_3d(\n",
    "    df_corporate_split,\n",
    "    x='total_order_value',\n",
    "    y='days_between_trans',\n",
    "    z='dog_share',\n",
    "    color='group',  # Use the combined group variable for color\n",
    "    symbol='group',  # Optionally, use different symbols for clarity\n",
    "    labels={\n",
    "        'total_order_value': 'Total Order Value',\n",
    "        'days_between_trans': 'Days Between Transactions',\n",
    "        'dog_share': 'Dog Share',\n",
    "        'group': 'Group'\n",
    "    }\n",
    ")\n",
    "fig.update_layout(\n",
    "    width=1600,\n",
    "    height=800,\n",
    "    title='Corporate Customers - 3D Scatter Plot with 2x2 Grid (Split by Mean)',\n",
    "    legend_title_text='Group (Total Order Value vs Num Transactions)'\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "# Set the found clusters as df_corporate['cluster']\n",
    "df_corporate['cluster'] = df_corporate_split['group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e92f2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import plotly.express as px\n",
    "\n",
    "# # Create a copy of the corporate customers dataframe\n",
    "# df_corporate_split = df_corporate.copy()\n",
    "\n",
    "# # Calculate the mean for total_order_value and num_transactions\n",
    "# mean_total_order_value = df_corporate_split['avg_order_value'].mean()\n",
    "# mean_num_transactions = df_corporate_split['num_transactions'].mean()\n",
    "\n",
    "# # Split based on whether the values are above or below the mean\n",
    "# df_corporate_split['total_order_value_split'] = df_corporate_split['avg_order_value'].apply(\n",
    "#     lambda x: 'low' if x < mean_total_order_value else 'high'\n",
    "# )\n",
    "\n",
    "# df_corporate_split['num_transactions_split'] = df_corporate_split['num_transactions'].apply(\n",
    "#     lambda x: 'low' if x < mean_num_transactions else 'high'\n",
    "# )\n",
    "\n",
    "# # Combine the two splits into a single group variable for four distinct categories\n",
    "# df_corporate_split['group'] = (\n",
    "#     df_corporate_split['total_order_value_split'].astype(str) + '_' +\n",
    "#     df_corporate_split['num_transactions_split'].astype(str)\n",
    "# )\n",
    "\n",
    "# # Visualize the 2x2 grid in a 3D scatter plot with four different colors\n",
    "# fig = px.scatter_3d(\n",
    "#     df_corporate_split,\n",
    "#     x='avg_order_value',\n",
    "#     y='days_between_trans',\n",
    "#     z='dog_share',\n",
    "#     color='group',  # Use the combined group variable for color\n",
    "#     symbol='group',  # Optionally, use different symbols for clarity\n",
    "#     labels={\n",
    "#         'avg_order_value': 'avg_order_value',\n",
    "#         'days_between_trans': 'Days Between Transactions',\n",
    "#         'dog_share': 'Dog Share',\n",
    "#         'group': 'Group'\n",
    "#     }\n",
    "# )\n",
    "# fig.update_layout(\n",
    "#     width=1600,\n",
    "#     height=800,\n",
    "#     title='Corporate Customers - 3D Scatter Plot with 2x2 Grid (Split by Mean)',\n",
    "#     legend_title_text='Group (Total Order Value vs Num Transactions)'\n",
    "# )\n",
    "# fig.show()\n",
    "\n",
    "# # Set the found clusters as df_corporate['cluster']\n",
    "# df_corporate['cluster'] = df_corporate_split['group']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1177a836",
   "metadata": {},
   "source": [
    "## 2x2 Matrix: Customer Segmentation Based on Total Order Value and Number of Transactions\n",
    "\n",
    "|                          | **Low Number of Transactions** <br> (Customers below Average Transactions Number) | **High Number of Transactions** <br> (Customers above Average Transactions Number) |\n",
    "|--------------------------|-----------------------------------------------------------------------------|-----------------------------------------------------------------------------|\n",
    "| **Low Total Order Value** <br> (Customers below Average Order Value) | **Budget-Conscious Occasional Customers** <br> These customers make infrequent purchases and spend a low total amount. They may be cost-sensitive or not heavily engaged. | **Budget-Conscious Frequent Customers** <br> These customers make frequent purchases but still maintain a relatively low total order value, indicating smaller transaction sizes. |\n",
    "| **High Total Order Value** <br> (Customers above Average Order Value) | **High-Spending Occasional Customers** <br> These customers do not transact often, but when they do, they tend to spend a significant amount. They might be selective but valuable. | **High-Spending Frequent Customers** <br> These are highly valuable customers who make frequent purchases with high total order value, indicating strong engagement and consistent spending. |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79613b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corporate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4dfaba",
   "metadata": {},
   "source": [
    "Having these 4 segmentations we can develop a marketing strategy customized for each one. When it comes to the dog_share value, there is no clear indication here for the different segments. It might be useful to simply split the dog_share value into 3 intervals and depending on each interval the content of the marketing strategy is adapted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3496f8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I would now like to use Altair to create a linked histogram that is filtered based on a selection of the scatter plot. Use the corporate customers dataframe for this task.\n",
    "import altair as alt\n",
    "\n",
    "# Create the scatter plot\n",
    "scatter = alt.Chart(df_corporate).mark_circle().encode(\n",
    "    x='avg_order_value',\n",
    "    y='days_between_trans',\n",
    "    color='repeat_share',\n",
    "    tooltip=['CustomerID', 'avg_order_value', 'days_between_trans', 'repeat_share']\n",
    ").properties(\n",
    "    width=800,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "# Create the histogram\n",
    "hist = alt.Chart(df_corporate).mark_bar().encode(\n",
    "    x='count()',\n",
    "    y='repeat_share',\n",
    "    color='repeat_share',\n",
    "    tooltip=['repeat_share']\n",
    ").properties(\n",
    "    width=800,\n",
    "    height=200\n",
    ").interactive()\n",
    "\n",
    "# Combine the scatter plot and the histogram\n",
    "scatter & hist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a306355",
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "\n",
    "# Scatter plot with color based on 'cluster'\n",
    "scatter_plot = alt.Chart(df_corporate).mark_circle(size=60).encode(\n",
    "    x=alt.X('avg_order_value', title='Average Order Value'),\n",
    "    y=alt.Y('days_between_trans', title='Days Between Transactions'),\n",
    "    color=alt.Color('cluster:N', scale=alt.Scale(scheme='category10'), title='Customer Segment'),\n",
    "    tooltip=['CustomerID', 'avg_order_value', 'days_between_trans', 'repeat_share']\n",
    ").properties(\n",
    "    width=1200,\n",
    "    height=800,\n",
    "    title=\"Customer Segments by Order Value and Days Between Transactions\"\n",
    ").interactive()\n",
    "\n",
    "scatter_plot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d38d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "\n",
    "# Prepare data for average metrics per cluster\n",
    "avg_metrics = df_corporate.groupby('cluster').agg(\n",
    "    avg_order_value=('avg_order_value', 'mean'),\n",
    "    avg_days_between_trans=('days_between_trans', 'mean'),\n",
    "    avg_repeat_share=('repeat_share', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "# Transform the data from wide format to long format for easier plotting\n",
    "avg_metrics_melted = avg_metrics.melt(id_vars='cluster', \n",
    "                                      value_vars=['avg_order_value', 'avg_days_between_trans', 'avg_repeat_share'], \n",
    "                                      var_name='Metric', \n",
    "                                      value_name='Value')\n",
    "\n",
    "# Bar chart for average metrics per cluster\n",
    "avg_bar_chart = alt.Chart(avg_metrics_melted).mark_bar().encode(\n",
    "    x=alt.X('Metric:N', title='Metric'),\n",
    "    y=alt.Y('Value:Q', title='Average Value'),\n",
    "    color=alt.Color('cluster:N', scale=alt.Scale(scheme='category10'), title='Customer Segment'),\n",
    "    column=alt.Column('cluster:N', title='Customer Segment'),\n",
    "    tooltip=['cluster', 'Metric', 'Value']\n",
    ").properties(\n",
    "    width=300,\n",
    "    height=600,\n",
    "    title=\"Average Metrics by Customer Segment\"\n",
    ").interactive()\n",
    "\n",
    "avg_bar_chart.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c11ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corporate['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebed5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of average order value vs days between transactions, color-coded by segment\n",
    "heatmap = alt.Chart(df_corporate).mark_rect().encode(\n",
    "    x=alt.X('avg_order_value:Q', bin=alt.Bin(maxbins=20), title='Average Order Value'),\n",
    "    y=alt.Y('days_between_trans:Q', bin=alt.Bin(maxbins=20), title='Days Between Transactions'),\n",
    "    color=alt.Color('count():Q', scale=alt.Scale(scheme='blues'), title='Customer Count'),\n",
    "    facet=alt.Facet('cluster:N', title='Customer Segment'),\n",
    "    tooltip=['avg_order_value', 'days_between_trans', 'cluster', 'count()']\n",
    ").properties(\n",
    "    width=300,\n",
    "    height=600,\n",
    "    title=\"Customer Distribution by Order Value and Transaction Frequency per Segment\"\n",
    ").interactive()\n",
    "\n",
    "heatmap.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d0a67f",
   "metadata": {},
   "source": [
    "## Private Customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368f0c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index of df_private\n",
    "df_private = df_private.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cd62db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the corporate customers\n",
    "fig = px.scatter_3d(df_private, x='avg_order_value', y='days_between_trans', z='dog_share', color='repeat_share')\n",
    "\n",
    "# Set the size of the figure\n",
    "fig.update_layout(width=1600, height=800)\n",
    "\n",
    "fig.update_layout(title='Corporate Customers - 3D Scatter Plot')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddab2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the corporate customers\n",
    "fig = px.scatter_3d(df_private, x='total_order_value', y='days_between_trans', z='dog_share', color='repeat_share')\n",
    "\n",
    "# Set the size of the figure\n",
    "fig.update_layout(width=1600, height=800)\n",
    "\n",
    "fig.update_layout(title='Corporate Customers - 3D Scatter Plot')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58427d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster one group out of the private customers. These are the ones with days_between_trans of below 5. Filter them out and create a new dataframe\n",
    "df_private_cluster1 = df_private[df_private['days_between_trans'] < 5]\n",
    "df_private_cluster1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a6fc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create df_private_cluster2 by filtering out the private customers that are in df_private_cluster1\n",
    "df_private_cluster_rest = df_private[~df_private['CustomerID'].isin(df_private_cluster1['CustomerID'])]\n",
    "df_private_cluster_rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13ac529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the corporate customers\n",
    "fig = px.scatter_3d(df_private_cluster_rest, x='avg_order_value', y='days_between_trans', z='dog_share', color='repeat_share')\n",
    "\n",
    "# Set the size of the figure\n",
    "fig.update_layout(width=1600, height=800)\n",
    "\n",
    "fig.update_layout(title='Corporate Customers - 3D Scatter Plot')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e40501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the corporate customers\n",
    "fig = px.scatter_3d(df_private_cluster_rest, x='total_order_value', y='days_between_trans', z='dog_share', color='repeat_share')\n",
    "\n",
    "# Set the size of the figure\n",
    "fig.update_layout(width=1600, height=800)\n",
    "\n",
    "fig.update_layout(title='Corporate Customers - 3D Scatter Plot')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197145f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now I want to use Altair to create a scatter plot for the private customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f43d9e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a3bf0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe9f10e7",
   "metadata": {},
   "source": [
    "Now filter out dog food related customers who order every 6 month or only once in the time frame and that might get won back with special dog related marketing offers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d7c4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now filter out cluster2 from the private customers. These are the ones with a repeat_share of below 0.3 but a dog_share of above 0.29\n",
    "df_private_cluster2 = df_private_cluster_rest[(df_private_cluster_rest['repeat_share'] < 0.3) & (df_private_cluster_rest['dog_share'] > 0.25)]\n",
    "\n",
    "# Create df_private_cluster3 by filtering out the private customers that are in df_private_cluster2\n",
    "df_private_cluster_rest = df_private_cluster_rest[~df_private_cluster_rest['CustomerID'].isin(df_private_cluster2['CustomerID'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd666089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the corporate customers\n",
    "fig = px.scatter_3d(df_private_cluster_rest, x='total_order_value', y='days_between_trans', z='dog_share', color='repeat_share')\n",
    "\n",
    "# Set the size of the figure\n",
    "fig.update_layout(width=1600, height=800)\n",
    "\n",
    "fig.update_layout(title='Corporate Customers - 3D Scatter Plot')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46374a89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7710d201",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637d0311",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d375fe2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1549d425",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaac14d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3052aedd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08ab8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use k-means to cluster the private customers into three groups\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Create a copy of the private customers dataframe\n",
    "df_private_cluster = df_private.copy()\n",
    "\n",
    "# Drop the CustomerID column, the total_order_value column and the num_transactions column\n",
    "df_private_cluster = df_private_cluster.drop(columns=['CustomerID', 'total_order_value'])\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the data\n",
    "df_private_cluster_scaled = scaler.fit_transform(df_private_cluster)\n",
    "\n",
    "# Create the KMeans model with 3 clusters\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "kmeans.fit(df_private_cluster_scaled)\n",
    "\n",
    "# Add the cluster labels to the dataframe\n",
    "df_private['cluster'] = kmeans.labels_\n",
    "\n",
    "# Visualize the clusters in a 3D scatter plot\n",
    "fig = px.scatter_3d(df_private, x='avg_order_value', y='days_between_trans', z='dog_share', color='cluster')\n",
    "fig.update_layout(width=1600, height=800)\n",
    "fig.update_layout(title='Private Customers - 3D Scatter Plot with Clusters')\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229a3e77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2d19e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899104eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8190282",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccd0e68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5001e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7ebbf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a3e73b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903f8a2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13c0c37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742421f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8c73b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3b3ed1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787c554f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f2a636",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dcfa6f92",
   "metadata": {},
   "source": [
    "### Scaling Features for further Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6f6bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scaling Features\n",
    "# Create a copy of the dataframe\n",
    "df_scaled = df.copy()\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the data\n",
    "df_scaled[['num_transactions', 'total_order_value', 'days_between_trans', 'repeat_share', 'dog_share']] = scaler.fit_transform(df[['num_transactions', 'total_order_value', 'days_between_trans', 'repeat_share', 'dog_share']])\n",
    "df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4294305b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the summary statistics of the scaled data\n",
    "df_scaled.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab4b586",
   "metadata": {},
   "source": [
    "# Clustering and Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0f8d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Try out more Cluster algorithms and see which one fits the best\n",
    "#TODO: Try out more Dimensionality Reduction algorithms and see which one fits the best\n",
    "#TODO: Try to generate more features and see if the model improves\n",
    "#TODO: Try different number of clusters to find a better optimum (Elbow Method or Silhouette Score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7294d08c",
   "metadata": {},
   "source": [
    "We can use a 3 cluster segmentation in which we describe a high quality, medium quality and low quality customer.\n",
    "\n",
    "The high quality customer is a customer that has a high number of transactions, a high total order value, a low days between transactions, a high repeat share and a high dog share.\n",
    "\n",
    "The low and medium quality customer accordingly. We create a lead score for each customer based on the above features and then segment the customers into 3 clusters.\n",
    "\n",
    "We can then adjust our marketing strategy to target the high quality customers more effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730df6ae",
   "metadata": {},
   "source": [
    "## Choosing the Clustering Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109c5424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First try the k-means clustering algorithm\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Create a copy of the final dataframe and drop the CustomerID column\n",
    "df_scaled_cluster = df_scaled.copy().drop('CustomerID', axis=1)\n",
    "\n",
    "# Initialize the KMeans algorithm\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "\n",
    "# Fit the algorithm to the data\n",
    "df_scaled_cluster['Cluster'] = kmeans.fit_predict(df_scaled_cluster)\n",
    "df_scaled_cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e671ef33",
   "metadata": {},
   "source": [
    "# Evaluation of Segments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da0c0da",
   "metadata": {},
   "source": [
    "## Analyzing Cluster Characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911c8481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean of the clusters\n",
    "cluster_stats = df_scaled_cluster.groupby('Cluster').mean()\n",
    "cluster_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf6ba35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of customers in each cluster\n",
    "cluster_size = df_scaled_cluster['Cluster'].value_counts().reset_index()\n",
    "cluster_size.columns = ['Cluster', 'Count']\n",
    "\n",
    "# Calculate the distribution of each cluster\n",
    "cluster_dist = cluster_size['Count'] / cluster_size['Count'].sum()\n",
    "cluster_size['Distribution'] = cluster_dist\n",
    "cluster_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3285893",
   "metadata": {},
   "source": [
    "## Model Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d4dd7a",
   "metadata": {},
   "source": [
    "### Calculating Commonly Used Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8439bf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the silhouette score\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "silhouette_score(df_scaled_cluster.drop('Cluster', axis=1), df_scaled_cluster['Cluster'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b0af46",
   "metadata": {},
   "source": [
    "A score of more than 0.5 indicates a high-quality cluster. In our case it of course depends on the application of our clusters. If we are looking for a small number of high-quality customers, the results indicate that we could have already found them. Lets check the results further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7479924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Davies-Bouldin Index\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "\n",
    "davies_bouldin_score(df_scaled_cluster.drop('Cluster', axis=1), df_scaled_cluster['Cluster'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20644529",
   "metadata": {},
   "source": [
    "### Visualizing the Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14226cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results of the clustering by using the Cluster column and the num_transactions and total_order_value columns\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='repeat_share', y='dog_share', hue='Cluster', data=df_scaled_cluster, palette='viridis')\n",
    "plt.title('KMeans Clustering Results')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e9dac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results of the clustering by using the Cluster column and the num_transactions and total_order_value columns\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='num_transactions', y='total_order_value', hue='Cluster', data=df_scaled_cluster, palette='viridis')\n",
    "plt.title('KMeans Clustering Results')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47cfb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results of the clustering by using the Cluster column and the num_transactions and total_order_value columns\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='total_order_value', y='days_between_trans', hue='Cluster', data=df_scaled_cluster, palette='viridis')\n",
    "plt.title('KMeans Clustering Results')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355068a7",
   "metadata": {},
   "source": [
    "We can clearly see already that the clustering gives us a good segmentation of the customers. It is especially helpful to find the high quality customers that we want to explicitly target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4b8d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the Cluster column to the final dataframe\n",
    "df_final['Cluster'] = df_scaled_cluster['Cluster']\n",
    "\n",
    "# Visualize the cluster plots using PCA\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='PCA1', y='PCA2', hue='Cluster', data=df_final, palette='viridis')\n",
    "plt.title('KMeans Clustering Results with PCA')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1715421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Visualize the cluster plots using t-SNE\n",
    "# from sklearn.manifold import TSNE\n",
    "\n",
    "# # Initialize the t-SNE algorithm\n",
    "# tsne = TSNE(n_components=2, random_state=42)\n",
    "\n",
    "# # Fit and transform the data\n",
    "# df_tsne = tsne.fit_transform(df_scaled_cluster.drop('Cluster', axis=1))\n",
    "\n",
    "# # Create a dataframe with the t-SNE components\n",
    "# df_tsne = pd.DataFrame(data=df_tsne, columns=['t-SNE1', 't-SNE2'])\n",
    "\n",
    "# # Concatenate the t-SNE components with the cluster column\n",
    "# df_tsne = pd.concat([df_tsne, df_scaled_cluster['Cluster']], axis=1)\n",
    "\n",
    "# # Visualize the cluster plots using t-SNE\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# sns.scatterplot(x='t-SNE1', y='t-SNE2', hue='Cluster', data=df_tsne, palette='viridis')\n",
    "# plt.title('KMeans Clustering Results with t-SNE')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0a5a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use plotly to create a 3D scatter plot of the clusters\n",
    "fig = px.scatter_3d(df_scaled_cluster, x='num_transactions', y='total_order_value', z='days_between_trans', color='Cluster', opacity=0.7)\n",
    "fig.update_layout(title='KMeans Clustering Results in 3D')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee68fb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use plotly to create a 3D scatter plot of the clusters\n",
    "fig = px.scatter_3d(df_scaled_cluster, x='num_transactions', y='repeat_share', z='dog_share', color='Cluster', opacity=0.7)\n",
    "fig.update_layout(title='KMeans Clustering Results in 3D')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d850d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use plotly to create a 3D scatter plot of the clusters\n",
    "fig = px.scatter_3d(df_scaled_cluster, x='num_transactions', y='days_between_trans', z='repeat_share', color='Cluster', opacity=0.7)\n",
    "fig.update_layout(title='KMeans Clustering Results in 3D')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884ed219",
   "metadata": {},
   "source": [
    "In this section we closely looked at the clusters and the characteristics of the customers in each cluster. We also validated the model by calculating commonly used scores and visualizing the clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0587ea1f",
   "metadata": {},
   "source": [
    "# Final Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43fcf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge df_scaled['CustomerID'] with df_scaled_cluster['Cluster']\n",
    "df_clustered = pd.concat([df_scaled['CustomerID'], df_scaled_cluster['Cluster']], axis=1)\n",
    "df_clustered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb50a1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the clustered data to a CSV file\n",
    "df_clustered.to_csv('Clustered_Data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2fedc5",
   "metadata": {},
   "source": [
    "# Conclusion and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce315c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Make create a Report that looks professional and is easy to understand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91f5930",
   "metadata": {},
   "source": [
    "## Business Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c15adef",
   "metadata": {},
   "source": [
    "## Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861ce1da",
   "metadata": {},
   "source": [
    "1. Having found the customer segments, it is now the next step to target these different segments in the correct way.\n",
    "2. Offer them simple solutions for each customer segmentation that they can straight away use.\n",
    "3. Sell them a follow up project for a more advanced solution (creating a 'Save the running away customers' by creating a model that can customize the advertisement and special offer)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c7764d",
   "metadata": {},
   "source": [
    "4. With a longer history of at least 2-3 years we can implement a Customer Lifetime Value model which helps to find out which customers to invest in (using PyMC-Marketing library https://github.com/pymc-labs/pymc-marketing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383ea439",
   "metadata": {},
   "source": [
    "Think about the total structure of the notebook at the end again. Maybe show at the beginning how the notebook is structured and what we are going to find (Top Level Overview and then Linear Down)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f34e41",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "3fcbd7240ee8f908d933dc7f71e8c42a1a91163b70ede8dcff5146d4087436c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
